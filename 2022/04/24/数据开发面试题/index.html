<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="HadoopHadoop基础先说下Hadoop是什么Hadoop是一个分布式系统基础架构，主要是为了解决海量数据的存储和海量数据的分析计算问题。 说下Hadoop核心组件Hadoop自诞生以来，主要有Hadoop 1.x、2.x、3.x三个系列多个版本； Hadoop 1.x组成：HDFS（具有高可靠性、高吞吐量的分布式文件系统，用于数据存储），MapReduce（同时处理业务逻辑运算和资源的调度">
<meta property="og:type" content="article">
<meta property="og:title" content="数据开发面试题">
<meta property="og:url" content="http://example.com/2022/04/24/%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/index.html">
<meta property="og:site_name" content="珍品菲尔的博客">
<meta property="og:description" content="HadoopHadoop基础先说下Hadoop是什么Hadoop是一个分布式系统基础架构，主要是为了解决海量数据的存储和海量数据的分析计算问题。 说下Hadoop核心组件Hadoop自诞生以来，主要有Hadoop 1.x、2.x、3.x三个系列多个版本； Hadoop 1.x组成：HDFS（具有高可靠性、高吞吐量的分布式文件系统，用于数据存储），MapReduce（同时处理业务逻辑运算和资源的调度">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.1.3.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.5HDFS块.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.7HDFS写数据流程.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.7HDFS读数据流程.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.8secondary%20namenode工作机制.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.10HDFS组成架构.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.11HAnamenode工作机制.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.12机架感知.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.12HDFS读.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.12HDFS读.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.12HDFS写详细版.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.2.12HDFS读详细版.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.3.7MapTask工作机制.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.3.7ReduceTask工作机制.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.3.8mapReduce中shuffle阶段的工作流程.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.3.9mapReduce中combiner作用.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.4.3MapReduce数据压缩.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/1.4.7YARN基础架构.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/2.1.1HQL转化成MapReduce.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/2.1.3Hive架构.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/2.1.3Hive运行机制.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/2.2.2HSQL转MR（1）.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/2.2.2HSQL转MR（2）.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/2.2.3Hive底层与数据库交互原理.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/2.2.5Hive和RDBMS异同.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/3.1kafka-介绍下Kafka01.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/3.2.3Kafka简单架构.jpg">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/3.2.3Kafka详细架构.jpg">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/3.2.6数据一致性.jpg">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/3.2.16Kafka分区分配策略.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/3.3.4Kafka中broker的意义.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/4.1HBase架构.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/4.1HBase-架构-HFile.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/4.1HBase-架构-HFile结构.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/4.2.6HBase和Hive区别.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/4.2.6HBase中scan对象的setCache和setBatch方法.png">
<meta property="og:image" content="http://example.com/images/bigDataGuideImgs/4.2.6HBase%20Table.png">
<meta property="article:published_time" content="2022-04-24T06:32:34.000Z">
<meta property="article:modified_time" content="2022-04-24T07:03:08.520Z">
<meta property="article:author" content="cuanHaoQi">
<meta property="article:tag" content="bigdata">
<meta property="article:tag" content="面试">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="Hive">
<meta property="article:tag" content="Kafka">
<meta property="article:tag" content="HBase">
<meta property="article:tag" content="Spark">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/bigDataGuideImgs/1.1.3.png">

<link rel="canonical" href="http://example.com/2022/04/24/%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>数据开发面试题 | 珍品菲尔的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">珍品菲尔的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Lifetime Learner</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/24/%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="cuanHaoQi">
      <meta itemprop="description" content="时间顺流而下，生活逆水行舟">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="珍品菲尔的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          数据开发面试题
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-04-24 14:32:34 / 修改时间：15:03:08" itemprop="dateCreated datePublished" datetime="2022-04-24T14:32:34+08:00">2022-04-24</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="Hadoop基础"><a href="#Hadoop基础" class="headerlink" title="Hadoop基础"></a>Hadoop基础</h2><h3 id="先说下Hadoop是什么"><a href="#先说下Hadoop是什么" class="headerlink" title="先说下Hadoop是什么"></a>先说下Hadoop是什么</h3><p>Hadoop是一个分布式系统基础架构，主要是为了解决海量数据的存储和海量数据的分析计算问题。</p>
<h3 id="说下Hadoop核心组件"><a href="#说下Hadoop核心组件" class="headerlink" title="说下Hadoop核心组件"></a>说下Hadoop核心组件</h3><p>Hadoop自诞生以来，主要有Hadoop 1.x、2.x、3.x三个系列多个版本；</p>
<p>Hadoop 1.x组成：HDFS（具有高可靠性、高吞吐量的分布式文件系统，用于数据存储），MapReduce（同时处理业务逻辑运算和资源的调度），Common（辅助工具，为其它Hadoop模块提供基础设施）；</p>
<p>Hadoop 2.x和Hadoop 3.x组成上无变化，和Hadoop 1.x相比，增加了YARN，分担了MapReduce的工作，组件包括：HDFS（具有高可靠性、高吞吐量的分布式文件系统，用于数据存储），MapReduce（处理业务逻辑运算），YARN（负责作业调度与集群资源管理），Common（辅助工具，为其它Hadoop模块提供基础设施）。</p>
<span id="more"></span>
<h3 id="Hadoop核心组件作用"><a href="#Hadoop核心组件作用" class="headerlink" title="Hadoop核心组件作用"></a>Hadoop核心组件作用</h3><p><img src="/images/bigDataGuideImgs/1.1.3.png"></p>
<p>Hadoop主要组件如上图，主要是HDFS、MapReduce、YARN、Common</p>
<p><strong>HDFS</strong></p>
<p>HDFS是一个文件系统，用于存储文件，通过目录树来定位文件。</p>
<p>其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p>
<p>HDFS 的使用场景：适合一次写入，多次读出的场景。一个文件经过创建、写入和关闭之后就不需要改变。</p>
<p><strong>MapReduce</strong></p>
<p>MapReduce是一个分布式运算程序的编程框架，是用户开发“基于Hadoop的数据分析应用”的核心框架。</p>
<p>MapReduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个Hadoop集群上。</p>
<p>MapReduce将计算过程分为两个阶段：<strong>Map和Reduce</strong></p>
<p>Map阶段并行处理输入数据</p>
<p>Reduce阶段对Map结果进行汇总</p>
<p><strong>YARN</strong></p>
<p>先来看两个问题，在Hadoop中</p>
<p>如何管理集群资源？</p>
<p>如何给任务合理分配资源？</p>
<p>YARN在Hadoop中的作用，就是上面两个问题的答案。Yarn 是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而MapReduce等运算程序则相当于运行于操作系统之上的应用程序。</p>
<p><strong>Common</strong></p>
<p>Hadoop体系最底层的一个模块，为Hadoop各子项目提供各种工具，如：配置文件和日志操作等。</p>
<h3 id="集群的最主要瓶颈"><a href="#集群的最主要瓶颈" class="headerlink" title="集群的最主要瓶颈"></a>集群的最主要瓶颈</h3><p>&emsp; 磁盘IO  </p>
<h3 id="Hadoop运行模式"><a href="#Hadoop运行模式" class="headerlink" title="Hadoop运行模式"></a>Hadoop运行模式</h3><p>&emsp; 单机版、伪分布式模式、完全分布式模式  </p>
<h3 id="Hadoop生态圈的组件并做简要描述"><a href="#Hadoop生态圈的组件并做简要描述" class="headerlink" title="Hadoop生态圈的组件并做简要描述"></a>Hadoop生态圈的组件并做简要描述</h3><p>&emsp; 1）Zookeeper：是一个开源的分布式应用程序协调服务,基于zookeeper可以实现同步服务，配置维护，命名服务。<br>&emsp; 2）Flume：一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。<br>&emsp; 3）Hbase：是一个分布式的、面向列的开源数据库, 利用Hadoop HDFS作为其存储系统。<br>&emsp; 4）Hive：基于Hadoop的一个数据仓库工具，可以将结构化的数据档映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。<br>&emsp; 5）Sqoop：将一个关系型数据库中的数据导进到Hadoop的 HDFS中，也可以将HDFS的数据导进到关系型数据库中。  </p>
<h3 id="解释“hadoop”和“hadoop-生态系统”两个概念"><a href="#解释“hadoop”和“hadoop-生态系统”两个概念" class="headerlink" title="解释“hadoop”和“hadoop 生态系统”两个概念"></a>解释“hadoop”和“hadoop 生态系统”两个概念</h3><p>&emsp; Hadoop是指Hadoop框架本身；hadoop生态系统，不仅包含hadoop，还包括保证hadoop框架正常高效运行其他框架，比如zookeeper、Flume、Hbase、Hive、Sqoop等辅助框架。  </p>
<h3 id="请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么"><a href="#请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么" class="headerlink" title="请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么?"></a>请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么?</h3><p>&emsp; 1）NameNode：它是hadoop中的主服务器，管理文件系统名称空间和对集群中存储的文件的访问，保存有metadate。<br>&emsp; 2）SecondaryNameNode：它不是namenode的冗余守护进程，而是提供周期检查点和清理任务。帮助NN合并editslog，减少NN启动时间。<br>&emsp; 3）DataNode：它负责管理连接到节点的存储（一个集群中可以有多个节点）。每个存储数据的节点运行一个datanode守护进程。<br>&emsp; 4）ResourceManager（JobTracker）：JobTracker负责调度DataNode上的工作。每个DataNode有一个TaskTracker，它们执行实际工作。<br>&emsp; 5）NodeManager：（TaskTracker）执行任务。<br>&emsp; 6）DFSZKFailoverController：高可用时它负责监控NN的状态，并及时的把状态信息写入ZK。它通过一个独立线程周期性的调用NN上的一个特定接口来获取NN的健康状态。FC也有选择谁作为Active NN的权利，因为最多只有两个节点，目前选择策略还比较简单（先到先得，轮换）。<br>&emsp; 7）JournalNode：高可用情况下存放namenode的editlog文件。  </p>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><h3 id="HDFS-中的-block-默认保存几份？"><a href="#HDFS-中的-block-默认保存几份？" class="headerlink" title="HDFS 中的 block 默认保存几份？"></a>HDFS 中的 block 默认保存几份？</h3><p>&emsp; 默认保存3份  </p>
<h3 id="HDFS-默认-BlockSize-是多大？"><a href="#HDFS-默认-BlockSize-是多大？" class="headerlink" title="HDFS 默认 BlockSize 是多大？"></a>HDFS 默认 BlockSize 是多大？</h3><p>&emsp; Hadoop1.x 默认64MB, Hadoop 2.x 3.x默认128MB </p>
<h3 id="负责HDFS数据存储的是哪一部分？"><a href="#负责HDFS数据存储的是哪一部分？" class="headerlink" title="负责HDFS数据存储的是哪一部分？"></a>负责HDFS数据存储的是哪一部分？</h3><p>&emsp; DataNode负责数据存储  </p>
<h3 id="SecondaryNameNode的目的是什么？"><a href="#SecondaryNameNode的目的是什么？" class="headerlink" title="SecondaryNameNode的目的是什么？"></a>SecondaryNameNode的目的是什么？</h3><p>&emsp; 他的目的使帮助NameNode合并编辑日志，减少NameNode 启动时间  </p>
<h3 id="文件大小设置，增大有什么影响？"><a href="#文件大小设置，增大有什么影响？" class="headerlink" title="文件大小设置，增大有什么影响？"></a>文件大小设置，增大有什么影响？</h3><p>&emsp; HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M。<br>&emsp; <strong>思考：为什么块的大小不能设置的太小，也不能设置的太大？</strong><br>&emsp; &emsp; HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。如果块设置得足够大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。<br>因而，<strong>传输一个由多个块组成的文件的时间取决于磁盘传输速率</strong>。<br>&emsp; 如果寻址时间约为10ms，而传输速率为100MB/s，为了使寻址时间仅占传输时间的1%，我们要将块大小设置约为100MB。默认的块大小128MB。<br>&emsp; 块的大小：10ms×100×100M/s = 100M，如图<br><img src="/images/bigDataGuideImgs/1.2.5HDFS块.png"/></p>
<p>&emsp; 增加文件块大小，需要增加磁盘的传输速率。  </p>
<h3 id="hadoop的块大小，从哪个版本开始是128M"><a href="#hadoop的块大小，从哪个版本开始是128M" class="headerlink" title="hadoop的块大小，从哪个版本开始是128M"></a>hadoop的块大小，从哪个版本开始是128M</h3><p>&emsp; Hadoop1.x都是64M，hadoop2.x开始都是128M。  </p>
<h3 id="HDFS的存储机制（☆☆☆☆☆）"><a href="#HDFS的存储机制（☆☆☆☆☆）" class="headerlink" title="HDFS的存储机制（☆☆☆☆☆）"></a>HDFS的存储机制（☆☆☆☆☆）</h3><p>&emsp; HDFS存储机制，包括HDFS的<strong>写入数据过程</strong>和<strong>读取数据过程</strong>两部分<br>&emsp; <strong>HDFS写数据过程</strong>  </p>
<p><img src="/images/bigDataGuideImgs/1.2.7HDFS写数据流程.png"/>   </p>
<p>&emsp; 1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。<br>&emsp; 2）NameNode返回是否可以上传。<br>&emsp; 3）客户端请求第一个 block上传到哪几个datanode服务器上。<br>&emsp; 4）NameNode返回3个datanode节点，分别为dn1、dn2、dn3。<br>&emsp; 5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。<br>&emsp; 6）dn1、dn2、dn3逐级应答客户端。<br>&emsp; 7）客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3；<br>dn1每传一个packet会放入一个应答队列等待应答。<br>&emsp; 8）当一个block传输完成之后，客户端再次请求NameNode上传第二个block的服务器。（重复执行3-7步）。  </p>
<p>&emsp; <strong>HDFS读数据过程</strong>  </p>
<p><img src="/images/bigDataGuideImgs/1.2.7HDFS读数据流程.png"/>  </p>
<p>&emsp; 1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。<br>&emsp; 2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。<br>&emsp; 3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以packet为单位来做校验）。<br>&emsp; 4）客户端以packet为单位接收，先在本地缓存，然后写入目标文件。  </p>
<h3 id="secondary-namenode工作机制（☆☆☆☆☆）"><a href="#secondary-namenode工作机制（☆☆☆☆☆）" class="headerlink" title="secondary namenode工作机制（☆☆☆☆☆）"></a>secondary namenode工作机制（☆☆☆☆☆）</h3><p align="center">
<img src="/images/bigDataGuideImgs/1.2.8secondary namenode工作机制.png"/>  
<p align="center">
</p>
</p>  

<p><strong>1）第一阶段：NameNode启动</strong><br>&emsp; （1）第一次启动NameNode格式化后，创建fsimage和edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。<br>&emsp; （2）客户端对元数据进行增删改的请求。<br>&emsp; （3）NameNode记录操作日志，更新滚动日志。<br>&emsp; （4）NameNode在内存中对数据进行增删改查。<br><strong>2）第二阶段：Secondary NameNode工作</strong><br>&emsp; （1）Secondary NameNode询问NameNode是否需要checkpoint。直接带回NameNode是否检查结果。<br>&emsp; （2）Secondary NameNode请求执行checkpoint。<br>&emsp; （3）NameNode滚动正在写的edits日志。<br>&emsp; （4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。<br>&emsp; （5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。<br>&emsp; （6）生成新的镜像文件fsimage.chkpoint。<br>&emsp; （7）拷贝fsimage.chkpoint到NameNode。<br>&emsp; （8）NameNode将fsimage.chkpoint重新命名成fsimage。</p>
<h3 id="NameNode与SecondaryNameNode-的区别与联系？（☆☆☆☆☆）"><a href="#NameNode与SecondaryNameNode-的区别与联系？（☆☆☆☆☆）" class="headerlink" title="NameNode与SecondaryNameNode 的区别与联系？（☆☆☆☆☆）"></a>NameNode与SecondaryNameNode 的区别与联系？（☆☆☆☆☆）</h3><p><strong>机制流程看第7题</strong><br>1）区别<br>&emsp; （1）NameNode负责管理整个文件系统的元数据，以及每一个路径（文件）所对应的数据块信息。<br>&emsp; （2）SecondaryNameNode主要用于定期合并命名空间镜像和命名空间镜像的编辑日志。<br>2）联系：<br>&emsp; （1）SecondaryNameNode中保存了一份和namenode一致的镜像文件（fsimage）和编辑日志（edits）。<br>&emsp; （2）在主namenode发生故障时（假设没有及时备份数据），可以从SecondaryNameNode恢复数据。  </p>
<h3 id="HDFS组成架构（☆☆☆☆☆）"><a href="#HDFS组成架构（☆☆☆☆☆）" class="headerlink" title="HDFS组成架构（☆☆☆☆☆）"></a>HDFS组成架构（☆☆☆☆☆）</h3><p align="center">
<img src="/images/bigDataGuideImgs/1.2.10HDFS组成架构.png"/>  
<p align="center">
</p>
</p>  



<p>架构主要由四个部分组成，分别为<strong>HDFS Client、NameNode、DataNode和Secondary NameNode</strong>。下面我们分别介绍这四个组成部分。<br>1）Client：就是客户端。<br>&emsp; （1）文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行存储；<br>&emsp; （2）与NameNode交互，获取文件的位置信息；<br>&emsp; （3）与DataNode交互，读取或者写入数据；<br>&emsp; （4）Client提供一些命令来管理HDFS，比如启动或者关闭HDFS；<br>&emsp; （5）Client可以通过一些命令来访问HDFS；<br>2）NameNode：就是Master，它是一个主管、管理者。<br>&emsp; （1）管理HDFS的名称空间；<br>&emsp; （2）管理数据块（Block）映射信息；<br>&emsp; （3）配置副本策略；<br>&emsp; （4）处理客户端读写请求。<br>3）DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。<br>&emsp; （1）存储实际的数据块；<br>&emsp; （2）执行数据块的读/写操作。<br>4）Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。<br>&emsp; （1）辅助NameNode，分担其工作量；<br>&emsp; （2）定期合并Fsimage和Edits，并推送给NameNode；<br>&emsp; （3）在紧急情况下，可辅助恢复NameNode。  </p>
<h3 id="HAnamenode-是如何工作的-（☆☆☆☆☆）"><a href="#HAnamenode-是如何工作的-（☆☆☆☆☆）" class="headerlink" title="HAnamenode 是如何工作的? （☆☆☆☆☆）"></a>HAnamenode 是如何工作的? （☆☆☆☆☆）</h3><p align="center">
<img src="/images/bigDataGuideImgs/1.2.11HAnamenode工作机制.png"/>  
<p align="center">
</p>
</p>  


<p>ZKFailoverController主要职责<br>&emsp; 1）健康监测：周期性的向它监控的NN发送健康探测命令，从而来确定某个NameNode是否处于健康状态，如果机器宕机，心跳失败，那么zkfc就会标记它处于一个不健康的状态。<br>&emsp; 2）会话管理：如果NN是健康的，zkfc就会在zookeeper中保持一个打开的会话，如果NameNode同时还是Active状态的，那么zkfc还会在Zookeeper中占有一个类型为短暂类型的znode，当这个NN挂掉时，这个znode将会被删除，然后备用的NN，将会得到这把锁，升级为主NN，同时标记状态为Active。<br>&emsp; 3）当宕机的NN新启动时，它会再次注册zookeper，发现已经有znode锁了，便会自动变为Standby状态，如此往复循环，保证高可靠，需要注意，目前仅仅支持最多配置2个NN。<br>&emsp; 4）master选举：如上所述，通过在zookeeper中维持一个短暂类型的znode，来实现抢占式的锁机制，从而判断那个NameNode为Active状态  </p>
<h3 id="HDFS读写数据流程详解"><a href="#HDFS读写数据流程详解" class="headerlink" title="HDFS读写数据流程详解"></a>HDFS读写数据流程详解</h3><p>先来看下机架感知机制，也就是HDFS上副本存储结点的选择。</p>
<p><img src="/images/bigDataGuideImgs/1.2.12机架感知.png"></p>
<p>Hadoop3.x副本结点选择：</p>
<p>由上图可知，第一个副本在Client所处的节点上。如果客户端在集群外，随机选一个。</p>
<p>第二个副本在另一个机架的随机一个节点。</p>
<p>第三个副本在第二个副本所在机架的随机节点。</p>
<p><strong>关于HDFS读写流程，这里还是给出两个版本，有助于理解</strong></p>
<h4 id="第一个版本：简洁版"><a href="#第一个版本：简洁版" class="headerlink" title="第一个版本：简洁版"></a>第一个版本：简洁版</h4><p><strong>HDFS写数据流程</strong></p>
<p><img src="/images/bigDataGuideImgs/1.2.12HDFS读.png"></p>
<p>1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。   </p>
<p>2）NameNode返回是否可以上传。   </p>
<p>3）客户端请求第一个 block上传到哪几个datanode服务器上。   </p>
<p>4）NameNode返回3个datanode节点，分别为dn1、dn2、dn3。   </p>
<p>5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。   </p>
<p>6）dn1、dn2、dn3逐级应答客户端。   </p>
<p>7）客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。   </p>
<p>8）当一个block传输完成之后，客户端再次请求NameNode上传第二个block的服务器。（重复执行3-7步）。</p>
<p><strong>HDFS读数据流程</strong></p>
<p><img src="/images/bigDataGuideImgs/1.2.12HDFS读.png"></p>
<p>1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。   </p>
<p>2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。   </p>
<p>3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以packet为单位来做校验）。   </p>
<p>4）客户端以packet为单位接收，先在本地缓存，然后写入目标文件。</p>
<h4 id="第二个版本：详细版，有助于理解"><a href="#第二个版本：详细版，有助于理解" class="headerlink" title="第二个版本：详细版，有助于理解"></a>第二个版本：详细版，有助于理解</h4><p><strong>HDFS写数据流程</strong></p>
<p><img src="/images/bigDataGuideImgs/1.2.12HDFS写详细版.png"></p>
<p>1）Client将File按128M分块。分成两块，Block1和Block2;</p>
<p>2）Client向nameNode发送写数据请求，如图蓝色虚线①———&gt;。</p>
<p>3）NameNode节点，记录block信息。并返回可用的DataNode，如粉色虚线②———-&gt;。</p>
<pre><code>Block1: host2,host3,host1

Block2: host7,host8,host4
</code></pre><p>4）client向DataNode发送block1；发送过程是以流式写入。</p>
<p>流式写入过程：</p>
<p>（1）将64M的block1按64k的package划分;</p>
<p>（2）然后将第一个package发送给host2;</p>
<p>（3）host2接收完后，将第一个package发送给host3，同时client向host2发送第二个package；</p>
<p>（4）host3接收完第一个package后，发送给host1，同时接收host2发来的第二个package。</p>
<p>（5）以此类推，如图红线实线所示，直到将block1发送完毕。</p>
<p>（6）host2，host3，host1向NameNode，host2向Client发送通知，说“消息发送完了”。如图粉红颜色实线所示。</p>
<p>（7）client收到host2发来的消息后，向namenode发送消息，说我写完了。这样就完成了。如图黄色粗实线。</p>
<p>（8）发送完block1后，再向host7，host8，host4发送block2，如图蓝色实线所示。</p>
<p>（9）发送完block2后，host7，host8，host4向NameNode，host7向Client发送通知，如图浅绿色实线所示。</p>
<p>（10）client向NameNode发送消息，说我写完了，如图黄色粗实线。。。这样就完毕了。</p>
<p><strong>HDFS读数据流程</strong></p>
<p><img src="/images/bigDataGuideImgs/1.2.12HDFS读详细版.png"></p>
<p>1）client向namenode发送读请求。</p>
<p>2）namenode查看Metadata信息，返回fileA的block的位置。</p>
<pre><code>Block1: host2,host3,host1

Block2: host7,host8,host4
</code></pre><p>3）block的位置是有先后顺序的，先读block1，再读block2。而且block1去host2上读取；然后block2，去host7上读取。</p>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><h3 id="谈谈Hadoop序列化和反序列化及自定义bean对象实现序列化"><a href="#谈谈Hadoop序列化和反序列化及自定义bean对象实现序列化" class="headerlink" title="谈谈Hadoop序列化和反序列化及自定义bean对象实现序列化?"></a>谈谈Hadoop序列化和反序列化及自定义bean对象实现序列化?</h3><p>1）序列化和反序列化<br>&emsp; （1）序列化就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储（持久化）和网络传输。<br>&emsp; （2）反序列化就是将收到字节序列（或其他数据传输协议）或者是硬盘的持久化数据，转换成内存中的对象。<br>&emsp; （3）Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，header，继承体系等），不便于在网络中高效传输。所以，hadoop自己开发了一套序列化机制（Writable），精简、高效。<br>2）自定义bean对象要想序列化传输步骤及注意事项：<br>&emsp; （1）必须实现Writable接口<br>&emsp; （2）反序列化时，需要反射调用空参构造函数，所以必须有空参构造<br>&emsp; （3）重写序列化方法<br>&emsp; （4）重写反序列化方法<br>&emsp; （5）注意反序列化的顺序和序列化的顺序完全一致<br>&emsp; （6）要想把结果显示在文件中，需要重写toString()，且用”\t”分开，方便后续用<br>&emsp; （7）如果需要将自定义的bean放在key中传输，则还需要实现comparable接口，因为mapreduce框中的shuffle过程一定会对key进行排序  </p>
<h3 id="FileInputFormat切片机制（☆☆☆☆☆）"><a href="#FileInputFormat切片机制（☆☆☆☆☆）" class="headerlink" title="FileInputFormat切片机制（☆☆☆☆☆）"></a>FileInputFormat切片机制（☆☆☆☆☆）</h3><p>job提交流程源码详解<br>&emsp; waitForCompletion()<br>&emsp; submit();<br>&emsp; // 1、建立连接<br>&emsp; &emsp; connect();<br>&emsp; &emsp; &emsp; // 1）创建提交job的代理<br>&emsp; &emsp; &emsp; new Cluster(getConfiguration());<br>&emsp; &emsp; &emsp; &emsp; // （1）判断是本地yarn还是远程<br>&emsp; &emsp; &emsp; &emsp; initialize(jobTrackAddr, conf);<br>&emsp; // 2、提交job<br>&emsp; submitter.submitJobInternal(Job.this, cluster)<br>&emsp; &emsp; // 1）创建给集群提交数据的Stag路径<br>&emsp; &emsp; Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);<br>&emsp; &emsp; // 2）获取jobid ，并创建job路径<br>&emsp; &emsp; JobID jobId = submitClient.getNewJobID();<br>&emsp; &emsp; // 3）拷贝jar包到集群<br>&emsp; &emsp; copyAndConfigureFiles(job, submitJobDir);<br>&emsp; &emsp; rUploader.uploadFiles(job, jobSubmitDir);<br>&emsp; &emsp; // 4）计算切片，生成切片规划文件<br>&emsp; &emsp; writeSplits(job, submitJobDir);<br>&emsp; &emsp; maps = writeNewSplits(job, jobSubmitDir);<br>&emsp; &emsp; input.getSplits(job);<br>&emsp; &emsp; // 5）向Stag路径写xml配置文件<br>&emsp; &emsp; writeConf(conf, submitJobFile);<br>&emsp; &emsp; conf.writeXml(out);<br>&emsp; &emsp; // 6）提交job,返回提交状态<br>&emsp; &emsp; status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());  </p>
<h3 id="在一个运行的Hadoop-任务中，什么是InputSplit？（☆☆☆☆☆）"><a href="#在一个运行的Hadoop-任务中，什么是InputSplit？（☆☆☆☆☆）" class="headerlink" title="在一个运行的Hadoop 任务中，什么是InputSplit？（☆☆☆☆☆）"></a>在一个运行的Hadoop 任务中，什么是InputSplit？（☆☆☆☆☆）</h3><p>FileInputFormat源码解析(input.getSplits(job))<br>（1）找到你数据存储的目录。<br>（2）开始遍历处理（规划切片）目录下的每一个文件。<br>（3）遍历第一个文件ss.txt。<br>&emsp; a）获取文件大小fs.sizeOf(ss.txt);。<br>&emsp; b）计算切片大小computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M。<br>&emsp; c）<strong>默认情况下，切片大小=blocksize</strong>。<br>&emsp; d）开始切，形成第1个切片：ss.txt—0:128M 第2个切片ss.txt—128:256M 第3个切片ss.txt—256M:300M（每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，<strong>不大于1.1倍就划分一块切片</strong>）。<br>&emsp; e）将切片信息写到一个切片规划文件中。<br>&emsp; f）整个切片的核心过程在getSplit()方法中完成。<br>&emsp; g）数据切片只是在逻辑上对输入数据进行分片，并不会再磁盘上将其切分成分片进行存储。InputSplit只记录了分片的元数据信息，比如起始位置、长度以及所在的节点列表等。<br>&emsp; h）注意：block是HDFS上物理上存储的存储的数据，切片是对数据逻辑上的划分。<br>（4）<strong>提交切片规划文件到yarn上，yarn上的MrAppMaster就可以根据切片规划文件计算开启maptask个数</strong>。  </p>
<h3 id="如何判定一个job的map和reduce的数量"><a href="#如何判定一个job的map和reduce的数量" class="headerlink" title="如何判定一个job的map和reduce的数量?"></a>如何判定一个job的map和reduce的数量?</h3><p>1）map数量<br>&emsp; splitSize=max{minSize,min{maxSize,blockSize}}<br>&emsp; map数量由处理的数据分成的block数量决定default_num = total_size / split_size;<br>2）reduce数量<br>&emsp; reduce的数量job.setNumReduceTasks(x);x 为reduce的数量。不设置的话默认为 1。  </p>
<h3 id="Maptask的个数由什么决定？"><a href="#Maptask的个数由什么决定？" class="headerlink" title="Maptask的个数由什么决定？"></a>Maptask的个数由什么决定？</h3><p>&emsp; 一个job的map阶段MapTask并行度（个数），由客户端提交job时的切片个数决定。  </p>
<h3 id="MapTask和ReduceTask工作机制（☆☆☆☆☆）（也可回答MapReduce工作原理）"><a href="#MapTask和ReduceTask工作机制（☆☆☆☆☆）（也可回答MapReduce工作原理）" class="headerlink" title="MapTask和ReduceTask工作机制（☆☆☆☆☆）（也可回答MapReduce工作原理）"></a>MapTask和ReduceTask工作机制（☆☆☆☆☆）（也可回答MapReduce工作原理）</h3><p><strong>MapTask工作机制</strong></p>
<p align="center">
<img src="/images/bigDataGuideImgs/1.3.7MapTask工作机制.png"/>   
<p align="center">
</p>
</p>  

<p>（1）Read阶段：Map Task通过用户编写的RecordReader，从输入InputSplit中解析出一个个key/value。<br>（2）Map阶段：该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value。<br>（3）Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner），并写入一个环形内存缓冲区中。<br>（4）Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。<br>（5）Combine阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。  </p>
<p><strong>ReduceTask工作机制</strong></p>
<p align="center">
<img src="/images/bigDataGuideImgs/1.3.7ReduceTask工作机制.png"/>  
<p align="center">
</p>
</p>  

<p>（1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。<br>（2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。<br>（3）Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。 由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。<br>（4）Reduce阶段：reduce()函数将计算结果写到HDFS上。  </p>
<h3 id="描述mapReduce有几种排序及排序发生的阶段（☆☆☆☆☆）"><a href="#描述mapReduce有几种排序及排序发生的阶段（☆☆☆☆☆）" class="headerlink" title="描述mapReduce有几种排序及排序发生的阶段（☆☆☆☆☆）"></a>描述mapReduce有几种排序及排序发生的阶段（☆☆☆☆☆）</h3><p>1）排序的分类：<br>&emsp; （1）部分排序：<br>&emsp; &emsp; MapReduce根据输入记录的键对数据集排序。保证输出的每个文件内部排序。<br>&emsp; （2）全排序：<br>&emsp; &emsp; 如何用Hadoop产生一个全局排序的文件？最简单的方法是使用一个分区。但该方法在处理大型文件时效率极低，因为一台机器必须处理所有输出文件，从而完全丧失了MapReduce所提供的并行架构。<br>&emsp; &emsp; 替代方案：首先创建一系列排好序的文件；其次，串联这些文件；最后，生成一个全局排序的文件。主要思路是使用一个分区来描述输出的全局排序。例如：可以为待分析文件创建3个分区，在第一分区中，记录的单词首字母a-g，第二分区记录单词首字母h-n, 第三分区记录单词首字母o-z。<br>&emsp; （3）辅助排序：（GroupingComparator分组）<br>&emsp; &emsp; Mapreduce框架在记录到达reducer之前按键对记录排序，但键所对应的值并没有被排序。甚至在不同的执行轮次中，这些值的排序也不固定，因为它们来自不同的map任务且这些map任务在不同轮次中完成时间各不相同。一般来说，大多数MapReduce程序会避免让reduce函数依赖于值的排序。但是，有时也需要通过特定的方法对键进行排序和分组等以实现对值的排序。<br>&emsp; （4）二次排序：<br>&emsp; &emsp; 在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序。<br>2）自定义排序WritableComparable<br>&emsp; bean对象实现WritableComparable接口重写compareTo方法，就可以实现排序<br>&emsp; &emsp; @Override<br>&emsp; &emsp; public int compareTo(FlowBean o) {<br>&emsp; &emsp; &emsp; // 倒序排列，从大到小<br>&emsp; &emsp; &emsp; return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;<br>&emsp; &emsp; }<br>3）排序发生的阶段：<br>&emsp; （1）一个是在map side发生在spill后partition前。<br>&emsp; （2）一个是在reduce side发生在copy后 reduce前。  </p>
<h3 id="描述mapReduce中shuffle阶段的工作流程，如何优化shuffle阶段（☆☆☆☆☆）"><a href="#描述mapReduce中shuffle阶段的工作流程，如何优化shuffle阶段（☆☆☆☆☆）" class="headerlink" title="描述mapReduce中shuffle阶段的工作流程，如何优化shuffle阶段（☆☆☆☆☆）"></a>描述mapReduce中shuffle阶段的工作流程，如何优化shuffle阶段（☆☆☆☆☆）</h3><p><img src="/images/bigDataGuideImgs/1.3.8mapReduce中shuffle阶段的工作流程.png"/>  </p>
<p>分区，排序，溢写，拷贝到对应reduce机器上，增加combiner，压缩溢写的文件。  </p>
<h3 id="描述mapReduce中combiner的作用是什么，一般使用情景，哪些情况不需要，及和reduce的区别？"><a href="#描述mapReduce中combiner的作用是什么，一般使用情景，哪些情况不需要，及和reduce的区别？" class="headerlink" title="描述mapReduce中combiner的作用是什么，一般使用情景，哪些情况不需要，及和reduce的区别？"></a>描述mapReduce中combiner的作用是什么，一般使用情景，哪些情况不需要，及和reduce的区别？</h3><p>1）Combiner的意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量。<br>2）Combiner能够应用的前提是不能影响最终的业务逻辑，而且，Combiner的输出kv应该跟reducer的输入kv类型要对应起来。<br>3）Combiner和reducer的区别在于运行的位置。<br>&emsp; Combiner是在每一个maptask所在的节点运行；<br>&emsp; Reducer是接收全局所有Mapper的输出结果。  </p>
<p><img src="/images/bigDataGuideImgs/1.3.9mapReduce中combiner作用.png"/></p>
<h3 id="如果没有定义partitioner，那数据在被送达reducer前是如何被分区的？"><a href="#如果没有定义partitioner，那数据在被送达reducer前是如何被分区的？" class="headerlink" title="如果没有定义partitioner，那数据在被送达reducer前是如何被分区的？"></a>如果没有定义partitioner，那数据在被送达reducer前是如何被分区的？</h3><p>&emsp; 如果没有自定义的 partitioning，则默认的 partition 算法，即根据每一条数据的 key 的 hashcode 值摸运算（%）reduce 的数量，得到的数字就是“分区号“。  </p>
<h3 id="MapReduce-出现单点负载多大，怎么负载平衡？-（☆☆☆☆☆）"><a href="#MapReduce-出现单点负载多大，怎么负载平衡？-（☆☆☆☆☆）" class="headerlink" title="MapReduce 出现单点负载多大，怎么负载平衡？ （☆☆☆☆☆）"></a>MapReduce 出现单点负载多大，怎么负载平衡？ （☆☆☆☆☆）</h3><p>&emsp; 通过Partitioner实现  </p>
<h3 id="MapReduce-怎么实现-TopN？-（☆☆☆☆☆）"><a href="#MapReduce-怎么实现-TopN？-（☆☆☆☆☆）" class="headerlink" title="MapReduce 怎么实现 TopN？ （☆☆☆☆☆）"></a>MapReduce 怎么实现 TopN？ （☆☆☆☆☆）</h3><p>&emsp; 可以自定义groupingcomparator，对结果进行最大值排序，然后再reduce输出时，控制只输出前n个数。就达到了topn输出的目的。  </p>
<h3 id="Hadoop的缓存机制（Distributedcache）（☆☆☆☆☆）"><a href="#Hadoop的缓存机制（Distributedcache）（☆☆☆☆☆）" class="headerlink" title="Hadoop的缓存机制（Distributedcache）（☆☆☆☆☆）"></a>Hadoop的缓存机制（Distributedcache）（☆☆☆☆☆）</h3><p>&emsp; 分布式缓存一个最重要的应用就是在进行join操作的时候，如果一个表很大，另一个表很小，我们就可以将这个小表进行广播处理，即每个计算节点上都存一份，然后进行map端的连接操作，经过我的实验验证，这种情况下处理效率大大高于一般的reduce端join，广播处理就运用到了分布式缓存的技术。<br>&emsp; DistributedCache将拷贝缓存的文件到Slave节点在任何Job在节点上执行之前，文件在每个Job中只会被拷贝一次，缓存的归档文件会被在Slave节点中解压缩。将本地文件复制到HDFS中去，接着Client会通过addCacheFile() 和addCacheArchive()方法告诉DistributedCache在HDFS中的位置。当文件存放到文地时，JobClient同样获得DistributedCache来创建符号链接，其形式为文件的URI加fragment标识。当用户需要获得缓存中所有有效文件的列表时，JobConf 的方法 getLocalCacheFiles() 和getLocalArchives()都返回一个指向本地文件路径对象数组。  </p>
<h3 id="如何使用mapReduce实现两个表的join-（☆☆☆☆☆）"><a href="#如何使用mapReduce实现两个表的join-（☆☆☆☆☆）" class="headerlink" title="如何使用mapReduce实现两个表的join?（☆☆☆☆☆）"></a>如何使用mapReduce实现两个表的join?（☆☆☆☆☆）</h3><p>&emsp; 1）reduce side join : 在map阶段，map函数同时读取两个文件File1和File2，为了区分两种来源的key/value数据对，对每条数据打一个标签（tag）,比如：tag=0 表示来自文件File1，tag=2 表示来自文件File2。<br>&emsp; 2）map side join : Map side join 是针对以下场景进行的优化：两个待连接表中，有一个表非常大，而另一个表非常小，以至于小表可以直接存放到内存中。这样，我们可以将小表复制多份，让每个map task 内存中存在一份（比如存放到hash table 中），然后只扫描大表：对于大表中的每一条记录key/value，在hash table 中查找是否有相同的key 的记录，如果有，则连接后输出即可。  </p>
<h3 id="什么样的计算不能用mr来提速？"><a href="#什么样的计算不能用mr来提速？" class="headerlink" title="什么样的计算不能用mr来提速？"></a>什么样的计算不能用mr来提速？</h3><p>&emsp; 1）数据量很小。<br>&emsp; 2）繁杂的小文件。<br>&emsp; 3）索引是更好的存取机制的时候。<br>&emsp; 4）事务处理。<br>&emsp; 5）只有一台机器的时候。  </p>
<h3 id="ETL是哪三个单词的缩写"><a href="#ETL是哪三个单词的缩写" class="headerlink" title="ETL是哪三个单词的缩写"></a>ETL是哪三个单词的缩写</h3><p>&emsp; Extraction-Transformation-Loading的缩写，中文名称为数据提取、转换和加载。  </p>
<h3 id="介绍下MapReduce"><a href="#介绍下MapReduce" class="headerlink" title="介绍下MapReduce"></a>介绍下MapReduce</h3><p>可以结合MapReduce的优缺点一起回答</p>
<p>MapReduce 是一个分布式运算程序的编程框架，它的核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。</p>
<p>MapReduce的核心思想是将用户编写的逻辑代码和架构中的各个组件整合成一个分布式运算程序，实现一定程序的并行处理海量数据，提高效率。</p>
<p>海量数据难以在单机上处理，而一旦将单机版程序扩展到集群上进行分布式运行势必将大大增加程序的复杂程度。引入MapReduce架构，开发人员可以将精力集中于数据处理的核心业务逻辑上，而将分布式程序中的公共功能封装成框架,以降低开发的难度。</p>
<p>一个完整的mapreduce程序有三类实例进程</p>
<ul>
<li><p>MRAppMaster：负责整个程序的协调过程</p>
</li>
<li><p>MapTask：负责map阶段的数据处理</p>
</li>
<li><p>ReduceTask：负责reduce阶段的数据处理</p>
</li>
</ul>
<h3 id="MapReduce优缺点"><a href="#MapReduce优缺点" class="headerlink" title="MapReduce优缺点"></a>MapReduce优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p><strong>1）MapReduce 易于编程</strong></p>
<p>它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的 PC 机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得 MapReduce 编程变得非常流行。</p>
<p><strong>2）良好的扩展性</strong></p>
<p>当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</p>
<p><strong>3）高容错性</strong></p>
<p>MapReduce 设计的初衷就是使程序能够部署在廉价的 PC 机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行， 不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由 Hadoop 内部完成的。</p>
<p><strong>4）适合 PB 级以上海量数据的离线处理</strong></p>
<p>可以实现上千台服务器集群并发工作，提供数据处理能力。</p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p><strong>1）不擅长实时计算</strong></p>
<p>MapReduce无法像MySQL一样，在毫秒或者秒级内返回结果。</p>
<p><strong>2）不擅长流式计算</strong></p>
<p>流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为 MapReduce 自身的设计特点决定了数据源必须是静态的。</p>
<p><strong>3）不擅长 DAG（有向无环图）计算</strong></p>
<p>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘， 会造成大量的磁盘 IO，导致性能非常的低下。</p>
<h2 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h2><h3 id="简述hadoop1与hadoop2-的架构异同"><a href="#简述hadoop1与hadoop2-的架构异同" class="headerlink" title="简述hadoop1与hadoop2 的架构异同"></a>简述hadoop1与hadoop2 的架构异同</h3><p>&emsp; 1）加入了yarn解决了资源调度的问题。<br>&emsp; 2）加入了对zookeeper的支持实现比较可靠的高可用。  </p>
<h3 id="为什么会产生-yarn-它解决了什么问题，有什么优势？"><a href="#为什么会产生-yarn-它解决了什么问题，有什么优势？" class="headerlink" title="为什么会产生 yarn,它解决了什么问题，有什么优势？"></a>为什么会产生 yarn,它解决了什么问题，有什么优势？</h3><p>&emsp; 1）Yarn最主要的功能就是解决运行的用户程序与yarn框架完全解耦。<br>&emsp; 2）Yarn上可以运行各种类型的分布式运算程序（mapreduce只是其中的一种），比如mapreduce、storm程序，spark程序……  </p>
<h3 id="HDFS的数据压缩算法-（☆☆☆☆☆）"><a href="#HDFS的数据压缩算法-（☆☆☆☆☆）" class="headerlink" title="HDFS的数据压缩算法?（☆☆☆☆☆）"></a>HDFS的数据压缩算法?（☆☆☆☆☆）</h3><p>&emsp; Hadoop中常用的压缩算法有<strong>bzip2、gzip、lzo、snappy</strong>，其中lzo、snappy需要操作系统安装native库才可以支持。<br>&emsp; 数据可以压缩的位置如下所示。  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/1.4.3MapReduce数据压缩.png"/>  
<p align="center">
</p>
</p>  


<p>&emsp; <strong>企业开发用的比较多的是snappy</strong>。  </p>
<h3 id="Hadoop的调度器总结（☆☆☆☆☆）"><a href="#Hadoop的调度器总结（☆☆☆☆☆）" class="headerlink" title="Hadoop的调度器总结（☆☆☆☆☆）"></a>Hadoop的调度器总结（☆☆☆☆☆）</h3><p>（1）默认的调度器FIFO<br>&emsp; Hadoop中默认的调度器，它先按照作业的优先级高低，再按照到达时间的先后选择被执行的作业。<br>（2）计算能力调度器Capacity Scheduler<br>&emsp; 支持多个队列，每个队列可配置一定的资源量，每个队列采用FIFO调度策略，为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源量进行限定。调度时，首先按以下策略选择一个合适队列：计算每个队列中正在运行的任务数与其应该分得的计算资源之间的比值，选择一个该比值最小的队列；然后按以下策略选择该队列中一个作业：按照作业优先级和提交时间顺序选择，同时考虑用户资源量限制和内存限制。<br>（3）公平调度器Fair Scheduler<br>&emsp; 同计算能力调度器类似，支持多队列多用户，每个队列中的资源量可以配置，同一队列中的作业公平共享队列中所有资源。实际上，Hadoop的调度器远不止以上三种，最近，出现了很多针对新型应用的Hadoop调度器。  </p>
<h3 id="MapReduce-2-0-容错性（☆☆☆☆☆）"><a href="#MapReduce-2-0-容错性（☆☆☆☆☆）" class="headerlink" title="MapReduce 2.0 容错性（☆☆☆☆☆）"></a>MapReduce 2.0 容错性（☆☆☆☆☆）</h3><p>1）MRAppMaster容错性<br>&emsp; 一旦运行失败，由YARN的ResourceManager负责重新启动，最多重启次数可由用户设置，默认是2次。一旦超过最高重启次数，则作业运行失败。<br>2）Map Task/Reduce<br>&emsp; Task Task周期性向MRAppMaster汇报心跳；一旦Task挂掉，则MRAppMaster将为之重新申请资源，并运行之。最多重新运行次数可由用户设置，默认4次。  </p>
<h3 id="mapreduce推测执行算法及原理（☆☆☆☆☆）"><a href="#mapreduce推测执行算法及原理（☆☆☆☆☆）" class="headerlink" title="mapreduce推测执行算法及原理（☆☆☆☆☆）"></a>mapreduce推测执行算法及原理（☆☆☆☆☆）</h3><p>1）作业完成时间取决于最慢的任务完成时间<br>&emsp; 一个作业由若干个Map 任务和Reduce 任务构成。因硬件老化、软件Bug 等，某些任务可能运行非常慢。<br>&emsp; 典型案例：系统中有99%的Map任务都完成了，只有少数几个Map老是进度很慢，完不成，怎么办？<br>2）推测执行机制<br>&emsp; 发现拖后腿的任务，比如某个任务运行速度远慢于任务平均速度。为拖后腿任务启动一个备份任务，同时运行。谁先运行完，则采用谁的结果。<br>3）不能启用推测执行机制情况<br>&emsp; （1）任务间存在严重的负载倾斜；<br>&emsp; （2）特殊任务，比如任务向数据库中写数据。<br>4）算法原理<br>&emsp; 假设某一时刻，任务T的执行进度为progress，则可通过一定的算法推测出该任务的最终完成时刻estimateEndTime。另一方面，如果此刻为该任务启动一个备份任务，则可推断出它可能的完成时刻<code>estimateEndTime</code>,于是可得出以下几个公式：  </p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">estimateEndTime=estimatedRunTime+taskStartTime  </span><br><span class="line">estimatedRunTime=(currentTimestamp-taskStartTime)/progress  </span><br><span class="line">estimateEndTime`= currentTimestamp+averageRunTime</span><br></pre></td></tr></table></figure>
<p>&emsp; 其中，currentTimestamp为当前时刻；taskStartTime为该任务的启动时刻；averageRunTime为已经成功运行完成的任务的平均运行时间。这样，MRv2总是选择（estimateEndTime- estimateEndTime·）差值最大的任务，并为之启动备份任务。为了防止大量任务同时启动备份任务造成的资源浪费，MRv2为每个作业设置了同时启动的备份任务数目上限。<br>&emsp; 推测执行机制实际上采用了经典的算法优化方法：以空间换时间，它同时启动多个相同任务处理相同的数据，并让这些任务竞争以缩短数据处理时间。显然，这种方法需要占用更多的计算资源。在集群资源紧缺的情况下，应合理使用该机制，争取在多用少量资源的情况下，减少作业的计算时间。</p>
<h3 id="介绍下YARN"><a href="#介绍下YARN" class="headerlink" title="介绍下YARN"></a>介绍下YARN</h3><p>介绍YARN，可以先考虑下面两个问题</p>
<p>1）如何管理集群资源？</p>
<p>2）如何给任务合理分配资源？</p>
<p>YARN是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而MapReduce等运算程序则相当于运行于操作系统之上的应用程序。</p>
<p>YARN 作为一个资源管理、任务调度的框架，主要包含ResourceManager、NodeManager、ApplicationMaster和Container模块。</p>
<p><strong>YARN基础架构</strong></p>
<p><img src="/images/bigDataGuideImgs/1.4.7YARN基础架构.png"></p>
<p> 1）ResourceManager（RM）主要作用如下：</p>
<p>处理客户端请求</p>
<p>监控NodeManager</p>
<p>启动或监控ApplicationMaster</p>
<p>资源的分配与调度</p>
<p>2）NodeManager（NM）主要作用如下：</p>
<p>管理单个节点上的资源</p>
<p>处理来自ResourceManager的命令</p>
<p>处理来自ApplicationMaster的命令</p>
<p>3）ApplicationMaster（AM）作用如下：</p>
<p>为应用程序申请资源并分配给内部的任务</p>
<p>任务的监督与容错</p>
<p>4）Container</p>
<p>Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。</p>
<p>可以结合“YARN有什么优势，能解决什么问题？”一起回答</p>
<h2 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h2><h3 id="MapReduce跑得慢的原因？（☆☆☆☆☆）"><a href="#MapReduce跑得慢的原因？（☆☆☆☆☆）" class="headerlink" title="MapReduce跑得慢的原因？（☆☆☆☆☆）"></a>MapReduce跑得慢的原因？（<strong>☆☆☆☆☆</strong>）</h3><p>Mapreduce 程序效率的瓶颈在于两点：<br>1）计算机性能<br>&emsp; CPU、内存、磁盘健康、网络<br>2）I/O 操作优化<br>&emsp; （1）数据倾斜<br>&emsp; （2）map和reduce数设置不合理<br>&emsp; （3）reduce等待过久<br>&emsp; （4）小文件过多<br>&emsp; （5）大量的不可分块的超大文件<br>&emsp; （6）spill次数过多<br>&emsp; （7）merge次数过多等  </p>
<h3 id="MapReduce优化方法（☆☆☆☆☆）"><a href="#MapReduce优化方法（☆☆☆☆☆）" class="headerlink" title="MapReduce优化方法（☆☆☆☆☆）"></a>MapReduce优化方法（☆☆☆☆☆）</h3><p>1）数据输入<br>&emsp; （1）合并小文件：在执行mr任务前将小文件进行合并，大量的小文件会产生大量的map任务，增大map任务装载次数，而任务的装载比较耗时，从而导致mr运行较慢。<br>&emsp; （2）采用ConbinFileInputFormat来作为输入，解决输入端大量小文件场景。<br>2）map阶段<br>&emsp; （1）减少spill次数：通过调整io.sort.mb及sort.spill.percent参数值，增大触发spill的内存上限，减少spill次数，从而减少磁盘 IO。<br>&emsp; （2）减少merge次数：通过调整io.sort.factor参数，增大merge的文件数目，减少merge的次数，从而缩短mr处理时间。<br>&emsp; （3）在 map 之后先进行combine处理，减少I/O。<br>3）reduce阶段<br>&emsp; （1）合理设置map和reduce数：两个都不能设置太少，也不能设置太多。太少，会导致task等待，延长处理时间；太多，会导致 map、reduce任务间竞争资源，造成处理超时等错误。<br>&emsp; （2）设置map、reduce共存：调整slowstart.completedmaps参数，使map运行到一定程度后，reduce也开始运行，减少reduce的等待时间。<br>&emsp; （3）规避使用reduce，因为Reduce在用于连接数据集的时候将会产生大量的网络消耗。<br>&emsp; （4）合理设置reduce端的buffer，默认情况下，数据达到一个阈值的时候，buffer中的数据就会写入磁盘，然后reduce会从磁盘中获得所有的数据。也就是说，buffer和reduce是没有直接关联的，中间多个一个写磁盘-&gt;读磁盘的过程，既然有这个弊端，那么就可以通过参数来配置，使得buffer中的一部分数据可以直接输送到reduce，从而减少IO开销：mapred.job.reduce.input.buffer.percent，默认为0.0。当值大于0的时候，会保留指定比例的内存读buffer中的数据直接拿给reduce使用。这样一来，设置buffer需要内存，读取数据需要内存，reduce计算也要内存，所以要根据作业的运行情况进行调整。<br>4）IO传输<br>&emsp; （1）采用数据压缩的方式，减少网络IO的的时间。安装Snappy和LZOP压缩编码器。<br>&emsp; （2）使用SequenceFile二进制文件<br>5）数据倾斜问题<br>&emsp; （1）数据倾斜现象<br>&emsp; &emsp; 数据频率倾斜——某一个区域的数据量要远远大于其他区域。<br>&emsp; &emsp; 数据大小倾斜——部分记录的大小远远大于平均值。<br>&emsp; （2）如何收集倾斜数据<br>&emsp; &emsp; 在reduce方法中加入记录map输出键的详细情况的功能。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MAX_VALUES = <span class="string">&quot;skew.maxvalues&quot;</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> maxValueThreshold;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(JobConf job)</span> </span>&#123;</span><br><span class="line">     maxValueThreshold = job.getInt(MAX_VALUES, <span class="number">100</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterator&lt;Text&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">                     OutputCollector&lt;Text, Text&gt; output,</span></span></span><br><span class="line"><span class="function"><span class="params">                     Reporter reporter)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">     <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">     <span class="keyword">while</span> (values.hasNext()) &#123;</span><br><span class="line">         values.next();</span><br><span class="line">         i++;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">if</span> (++i &gt; maxValueThreshold) &#123;</span><br><span class="line">         log.info(<span class="string">&quot;Received &quot;</span> + i + <span class="string">&quot; values for key &quot;</span> + key);</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&emsp; （3）减少数据倾斜的方法<br>&emsp; &emsp; 方法1：抽样和范围分区<br>&emsp; &emsp; &emsp; 可以通过对原始数据进行抽样得到的结果集来预设分区边界值。<br>&emsp; &emsp; 方法2：自定义分区<br>&emsp; &emsp; &emsp; 另一个抽样和范围分区的替代方案是基于输出键的背景知识进行自定义分区。例如，如果map输出键的单词来源于一本书。其中大部分必然是省略词（stopword）。那么就可以将自定义分区将这部分省略词发送给固定的一部分reduce实例。而将其他的都发送给剩余的reduce实例。<br>&emsp; &emsp; 方法3：Combine<br>&emsp; &emsp; &emsp; 使用Combine可以大量地减小数据频率倾斜和数据大小倾斜。在可能的情况下，combine的目的就是聚合并精简数据。  </p>
<h3 id="HDFS小文件优化方法（☆☆☆☆☆）"><a href="#HDFS小文件优化方法（☆☆☆☆☆）" class="headerlink" title="HDFS小文件优化方法（☆☆☆☆☆）"></a>HDFS小文件优化方法（☆☆☆☆☆）</h3><p>1）HDFS小文件弊端：<br>&emsp; HDFS上每个文件都要在namenode上建立一个索引，这个索引的大小约为150byte，这样当小文件比较多的时候，就会产生很多的索引文件，一方面会大量占用namenode的内存空间，另一方面就是索引文件过大是的索引速度变慢。<br>2）解决的方式：<br>&emsp; （1）Hadoop本身提供了一些文件压缩的方案。<br>&emsp; （2）从系统层面改变现有HDFS存在的问题，其实主要还是小文件的合并，然后建立比较快速的索引。<br>3）Hadoop自带小文件解决方案<br>&emsp; （1）Hadoop Archive：<br>&emsp; &emsp; 是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样在减少namenode内存使用的同时。<br>&emsp; （2）Sequence file：<br>&emsp; &emsp; sequence file由一系列的二进制key/value组成，如果为key小文件名，value为文件内容，则可以将大批小文件合并成一个大文件。<br>&emsp; （3）CombineFileInputFormat：<br>&emsp; &emsp; CombineFileInputFormat是一种新的inputformat，用于将多个文件合并成一个单独的split，另外，它会考虑数据的存储位置。  </p>
<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="Hive概述"><a href="#Hive概述" class="headerlink" title="Hive概述"></a>Hive概述</h2><h3 id="什么是Hive"><a href="#什么是Hive" class="headerlink" title="什么是Hive"></a>什么是Hive</h3><p>&emsp; Hive是由Facebook开源用于解决海量结构化日志的数据统计。<br>&emsp; Hive是基于Hadoop的<strong>一个数据仓库工具</strong>，可以将结构化的数据文件映射为一张表，并<strong>提供类SQL查询功能</strong>。<br>&emsp; 本质是：<strong>将HQL转化成MapReduce程序</strong>  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/2.1.1HQL转化成MapReduce.png"/>  
<p align="center">
</p>
</p>  

<p>&emsp; 1）Hive处理的数据存储在HDFS<br>&emsp; 2）Hive分析数据底层的实现是MapReduce<br>&emsp; 3）执行程序运行在Yarn上  </p>
<p>Hive是Hadoop生态系统中比不可少的一个工具，它提供了一种SQL(结构化查询语言)方言，可以查询存储在Hadoop分布式文件系统（HDFS）中的数据或其他和Hadoop集成的文件系统，如MapR-FS、Amazon的S3和像HBase（Hadoop数据仓库）和Cassandra这样的数据库中的数据。</p>
<p>大多数数据仓库应用程序都是使用关系数据库进行实现的，并使用SQL作为查询语言。Hive降低了将这些应用程序转移到Hadoop系统上的难度。凡是会使用SQL语言的开发人员都可以很轻松的学习并使用Hive。如果没有Hive，那么这些用户就必须学习新的语言和工具，然后才能应用到生产环境中。另外，相比其他工具，Hive更便于开发人员将基于SQL的应用程序转移到Hadoop中。如果没有Hive，那么开发者将面临一个艰巨的挑战，如何将他们的SQL应用程序移植到Hadoop上。</p>
<h3 id="Hive优缺点"><a href="#Hive优缺点" class="headerlink" title="Hive优缺点"></a>Hive优缺点</h3><p><strong><code>优点</code></strong>：<br>&emsp; 1) 操作接口采用类SQL语法，提供快速开发的能力（简单、容易上手）。<br>&emsp; 2) 避免了去写MapReduce，减少开发人员的学习成本。<br>&emsp; 3) Hive的执行延迟比较高，因此Hive常用于数据分析，对实时性要求不高的场合。<br>&emsp; 4) Hive优势在于处理大数据，对于处理小数据没有优势，因为Hive的执行延迟比较高。<br>&emsp; 5) Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。<br><strong><code>缺点</code></strong>：<br>&emsp; 1）Hive的HQL表达能力有限<br>&emsp; &emsp; （1）迭代式算法无法表达<br>&emsp; &emsp; （2）数据挖掘方面不擅长<br>&emsp; 2）Hive的效率比较低<br>&emsp; &emsp; （1）Hive自动生成的MapReduce作业，通常情况下不够智能化<br>&emsp; &emsp; （2）Hive调优比较困难，粒度较粗  </p>
<p>Hive不是一个完整的数据库。Hadoop以及HDFS的设计本身约束和局限性地限制了Hive所能胜任的工作。其中最大的限制就是Hive不支持记录级别的更新、插入或者删除操作。但是用户可以通过查询生成新表或者将查询结果导入到文件中。同时，因为Hadoop是面向批处理的系统，而MapReduce任务（job）的启动过程需要消耗较长的时间，所以Hive查询延时比较严重。传统数据库中在秒级别可以完成的查询，在Hive中，即使数据集相对较小，往往也需要执行更长的时间。</p>
<h3 id="Hive架构原理"><a href="#Hive架构原理" class="headerlink" title="Hive架构原理"></a>Hive架构原理</h3><p align="center">
<img src="/images/bigDataGuideImgs/2.1.3Hive架构.png"/>  
<p align="center">
</p>
</p>  

<p>1）用户接口：Client<br>&emsp; CLI（command-line interface）、JDBC/ODBC(jdbc访问hive)、WEBUI（浏览器访问hive）<br>2）元数据：Metastore<br>&emsp; 元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；<br>&emsp; 默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore<br>3）Hadoop<br>&emsp; 使用HDFS进行存储，使用MapReduce进行计算。<br>4）驱动器：Driver<br>&emsp; （1）解析器（SQL Parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。<br>&emsp; （2）编译器（Physical Plan）：将AST编译生成逻辑执行计划。<br>&emsp; （3）优化器（Query Optimizer）：对逻辑执行计划进行优化。<br>&emsp; （4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/2.1.3Hive运行机制.png"/>  
<p align="center">
</p>
</p>  


<p>&emsp; Hive通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的Driver，结合元数据(MetaStore)，将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。 </p>
<h2 id="Hive面试题整理（一）"><a href="#Hive面试题整理（一）" class="headerlink" title="Hive面试题整理（一）"></a>Hive面试题整理（一）</h2><h3 id="Hive表关联查询，如何解决数据倾斜的问题？（☆☆☆☆☆）"><a href="#Hive表关联查询，如何解决数据倾斜的问题？（☆☆☆☆☆）" class="headerlink" title="Hive表关联查询，如何解决数据倾斜的问题？（☆☆☆☆☆）"></a>Hive表关联查询，如何解决数据倾斜的问题？（☆☆☆☆☆）</h3><p>&emsp; 1）倾斜原因：map输出数据按key Hash的分配到reduce中，由于key分布不均匀、业务数据本身的特、建表时考虑不周、等原因造成的reduce 上的数据量差异过大。<br>&emsp; （1）key分布不均匀;<br>&emsp; （2）业务数据本身的特性;<br>&emsp; （3）建表时考虑不周;<br>&emsp; （4）某些SQL语句本身就有数据倾斜;<br>&emsp; 如何避免：对于key为空产生的数据倾斜，可以对其赋予一个随机值。<br>&emsp; 2）解决方案<br>&emsp; （1）参数调节：<br>&emsp; &emsp; hive.map.aggr = true<br>&emsp; &emsp; hive.groupby.skewindata=true<br>&emsp; 有数据倾斜的时候进行负载均衡，当选项设定位true,生成的查询计划会有两个MR Job。第一个MR Job中，Map的输出结果集合会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key 分布到 Reduce 中（这个过程可以保证相同的 Group By Key 被分布到同一个Reduce中），最后完成最终的聚合操作。<br>&emsp; （2）SQL 语句调节：<br>&emsp; ① 选用join key分布最均匀的表作为驱动表。做好列裁剪和filter操作，以达到两表做join 的时候，数据量相对变小的效果。<br>&emsp; ② 大小表Join：<br>&emsp; &emsp; 使用map join让小的维度表（1000 条以下的记录条数）先进内存。在map端完成reduce。<br>&emsp; ③ 大表Join大表：<br>&emsp; &emsp; 把空值的key变成一个字符串加上随机数，把倾斜的数据分到不同的reduce上，由于null 值关联不上，处理后并不影响最终结果。<br>&emsp; ④ count distinct大量相同特殊值:<br>&emsp; &emsp; count distinct 时，将值为空的情况单独处理，如果是计算count distinct，可以不用处理，直接过滤，在最后结果中加1。如果还有其他计算，需要进行group by，可以先将值为空的记录单独处理，再和其他计算结果进行union。  </p>
<h3 id="Hive的HSQL转换为MapReduce的过程？（☆☆☆☆☆）"><a href="#Hive的HSQL转换为MapReduce的过程？（☆☆☆☆☆）" class="headerlink" title="Hive的HSQL转换为MapReduce的过程？（☆☆☆☆☆）"></a>Hive的HSQL转换为MapReduce的过程？（☆☆☆☆☆）</h3><p>&emsp; HiveSQL -&gt;AST(抽象语法树) -&gt; QB(查询块) -&gt;OperatorTree（操作树）-&gt;优化后的操作树-&gt;mapreduce任务树-&gt;优化后的mapreduce任务树  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/2.2.2HSQL转MR（1）.png"/>  
<p align="center">
</p>
</p>  

<p align="center">
<img src="/images/bigDataGuideImgs/2.2.2HSQL转MR（2）.png"/>  
<p align="center">
</p>
</p>  

<p>&emsp; 过程描述如下：<br>&emsp; &emsp; SQL Parser：Antlr定义SQL的语法规则，完成SQL词法，语法解析，将SQL转化为抽象语法树AST Tree；<br>&emsp; &emsp; Semantic Analyzer：遍历AST Tree，抽象出查询的基本组成单元QueryBlock；<br>&emsp; &emsp; Logical plan：遍历QueryBlock，翻译为执行操作树OperatorTree；<br>&emsp; &emsp; Logical plan optimizer: 逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量；<br>&emsp; &emsp; Physical plan：遍历OperatorTree，翻译为MapReduce任务；<br>&emsp; &emsp; Logical plan optimizer：物理层优化器进行MapReduce任务的变换，生成最终的执行计划。  </p>
<h3 id="Hive底层与数据库交互原理？（☆☆☆☆☆）"><a href="#Hive底层与数据库交互原理？（☆☆☆☆☆）" class="headerlink" title="Hive底层与数据库交互原理？（☆☆☆☆☆）"></a>Hive底层与数据库交互原理？（☆☆☆☆☆）</h3><p>&emsp; 由于Hive的元数据可能要面临不断地更新、修改和读取操作，所以它显然不适合使用Hadoop文件系统进行存储。目前Hive将元数据存储在RDBMS中，比如存储在MySQL、Derby中。元数据信息包括：存在的表、表的列、权限和更多的其他信息。  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/2.2.3Hive底层与数据库交互原理.png"/>  
<p align="center">
</p>
</p>  



<h3 id="Hive的两张表关联，使用MapReduce怎么实现？（☆☆☆☆☆）"><a href="#Hive的两张表关联，使用MapReduce怎么实现？（☆☆☆☆☆）" class="headerlink" title="Hive的两张表关联，使用MapReduce怎么实现？（☆☆☆☆☆）"></a>Hive的两张表关联，使用MapReduce怎么实现？（☆☆☆☆☆）</h3><p>&emsp; 如果其中有一张表为小表，直接使用map端join的方式（map端加载小表）进行聚合。<br>&emsp; 如果两张都是大表，那么采用联合key，联合key的第一个组成部分是join on中的公共字段，第二部分是一个flag，0代表表A，1代表表B，由此让Reduce区分客户信息和订单信息；在Mapper中同时处理两张表的信息，将join on公共字段相同的数据划分到同一个分区中，进而传递到一个Reduce中，然后在Reduce中实现聚合。  </p>
<h3 id="请谈一下Hive的特点，Hive和RDBMS有什么异同？"><a href="#请谈一下Hive的特点，Hive和RDBMS有什么异同？" class="headerlink" title="请谈一下Hive的特点，Hive和RDBMS有什么异同？"></a>请谈一下Hive的特点，Hive和RDBMS有什么异同？</h3><p>&emsp; hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析，但是Hive不支持实时查询。<br>&emsp; Hive与关系型数据库的区别：  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/2.2.5Hive和RDBMS异同.png"/>  
<p align="center">
</p>
</p>  



<h3 id="请说明hive中-Sort-By，Order-By，Cluster-By，Distrbute-By各代表什么意思？"><a href="#请说明hive中-Sort-By，Order-By，Cluster-By，Distrbute-By各代表什么意思？" class="headerlink" title="请说明hive中 Sort By，Order By，Cluster By，Distrbute By各代表什么意思？"></a>请说明hive中 Sort By，Order By，Cluster By，Distrbute By各代表什么意思？</h3><p>&emsp; order by：会对输入做全局排序，因此只有一个reducer（多个reducer无法保证全局有序）。只有一个reducer，会导致当输入规模较大时，需要较长的计算时间。<br>&emsp; sort by：不是全局排序，其在数据进入reducer前完成排序。<br>&emsp; distribute by：按照指定的字段对数据进行划分输出到不同的reduce中。<br>&emsp; cluster by：除了具有 distribute by 的功能外还兼具 sort by 的功能。  </p>
<h3 id="写出hive中split、coalesce及collect-list函数的用法（可举例）？"><a href="#写出hive中split、coalesce及collect-list函数的用法（可举例）？" class="headerlink" title="写出hive中split、coalesce及collect_list函数的用法（可举例）？"></a>写出hive中split、coalesce及collect_list函数的用法（可举例）？</h3><p>&emsp; split将字符串转化为数组，即：split(‘a,b,c,d’ , ‘,’) ==&gt; [“a”,”b”,”c”,”d”]。<br>&emsp; coalesce(T v1, T v2, …) 返回参数中的第一个非空值；如果所有值都为 NULL，那么返回NULL。<br>&emsp; collect_list列出该字段所有的值，不去重 =&gt; select collect_list(id) from table。  </p>
<h3 id="Hive有哪些方式保存元数据，各有哪些特点？"><a href="#Hive有哪些方式保存元数据，各有哪些特点？" class="headerlink" title="Hive有哪些方式保存元数据，各有哪些特点？"></a>Hive有哪些方式保存元数据，各有哪些特点？</h3><p>&emsp; Hive支持三种不同的元存储服务器，分别为：内嵌式元存储服务器、本地元存储服务器、远程元存储服务器，每种存储方式使用不同的配置参数。<br>&emsp; 内嵌式元存储主要用于单元测试，在该模式下每次只有一个进程可以连接到元存储，Derby是内嵌式元存储的默认数据库。<br>&emsp; 在本地模式下，每个Hive客户端都会打开到数据存储的连接并在该连接上请求SQL查询。<br>&emsp; 在远程模式下，所有的Hive客户端都将打开一个到元数据服务器的连接，该服务器依次查询元数据，元数据服务器和客户端之间使用Thrift协议通信。  </p>
<h3 id="Hive内部表和外部表的区别？"><a href="#Hive内部表和外部表的区别？" class="headerlink" title="Hive内部表和外部表的区别？"></a>Hive内部表和外部表的区别？</h3><p>&emsp; 创建表时：创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。<br>&emsp; 删除表时：在删除表的时候，内部表的元数据和数据会被一起删除， 而外部表只删除元数据，不删除数据。这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据。  </p>
<h3 id="Hive-中的压缩格式TextFile、SequenceFile、RCfile-、ORCfile各有什么区别？"><a href="#Hive-中的压缩格式TextFile、SequenceFile、RCfile-、ORCfile各有什么区别？" class="headerlink" title="Hive 中的压缩格式TextFile、SequenceFile、RCfile 、ORCfile各有什么区别？"></a>Hive 中的压缩格式TextFile、SequenceFile、RCfile 、ORCfile各有什么区别？</h3><p>&emsp; <strong>1、TextFile</strong><br>&emsp; 默认格式，<strong>存储方式为行存储，数据不做压缩，磁盘开销大，数据解析开销大</strong>。可结合Gzip、Bzip2使用(系统自动检查，执行查询时自动解压)，但使用这种方式，压缩后的文件不支持split，Hive不会对数据进行切分，从而无法对数据进行并行操作。并且在反序列化过程中，必须逐个字符判断是不是分隔符和行结束符，因此反序列化开销会比SequenceFile高几十倍。<br>&emsp; <strong>2、SequenceFile</strong><br>&emsp; SequenceFile是Hadoop API提供的一种二进制文件支持，<strong>存储方式为行存储，其具有使用方便、可分割、可压缩的特点</strong>。<br>&emsp; SequenceFile支持三种压缩选择：NONE，RECORD，BLOCK。Record压缩率低，<strong>一般建议使用BLOCK压缩</strong>。<br>&emsp; 优势是文件和hadoop api中的MapFile是相互兼容的<br>&emsp; <strong>3、RCFile</strong><br>&emsp; 存储方式：<strong>数据按行分块，每块按列存储</strong>。结合了行存储和列存储的优点：<br>&emsp; &emsp; 首先，RCFile 保证同一行的数据位于同一节点，因此元组重构的开销很低；<br>&emsp; &emsp; 其次，像列存储一样，RCFile 能够利用列维度的数据压缩，并且能跳过不必要的列读取；<br>&emsp; <strong>4、ORCFile</strong><br>&emsp; 存储方式：数据按行分块 每块按照列存储。<br>&emsp; 压缩快、快速列存取。<br>&emsp; 效率比rcfile高，是rcfile的改良版本。<br>&emsp; 总结：<strong>相比TEXTFILE和SEQUENCEFILE，RCFILE由于列式存储方式，数据加载时性能消耗较大，但是具有较好的压缩比和查询响应</strong>。<br>&emsp; <strong>数据仓库的特点是一次写入、多次读取，因此，整体来看，RCFILE相比其余两种格式具有较明显的优势</strong>。  </p>
<h3 id="所有的Hive任务都会有MapReduce的执行吗？"><a href="#所有的Hive任务都会有MapReduce的执行吗？" class="headerlink" title="所有的Hive任务都会有MapReduce的执行吗？"></a>所有的Hive任务都会有MapReduce的执行吗？</h3><p>&emsp; 不是，从Hive0.10.0版本开始，对于简单的不需要聚合的类似SELECT <col> from <table> LIMIT n语句，不需要起MapReduce job，直接通过Fetch task获取数据。  </p>
<h3 id="Hive的函数：UDF、UDAF、UDTF的区别？"><a href="#Hive的函数：UDF、UDAF、UDTF的区别？" class="headerlink" title="Hive的函数：UDF、UDAF、UDTF的区别？"></a>Hive的函数：UDF、UDAF、UDTF的区别？</h3><p>&emsp; UDF：单行进入，单行输出<br>&emsp; UDAF：多行进入，单行输出<br>&emsp; UDTF：单行输入，多行输出  </p>
<h3 id="说说对Hive桶表的理解？"><a href="#说说对Hive桶表的理解？" class="headerlink" title="说说对Hive桶表的理解？"></a>说说对Hive桶表的理解？</h3><p>&emsp; 桶表是对数据进行哈希取值，然后放到不同文件中存储。<br>&emsp; 数据加载到桶表时，会对字段取hash值，然后与桶的数量取模。把数据放到对应的文件中。物理上，每个桶就是表(或分区）目录里的一个文件，一个作业产生的桶(输出文件)和reduce任务个数相同。<br>&emsp; 桶表专门用于抽样查询，是很专业性的，不是日常用来存储数据的表，需要抽样查询时，才创建和使用桶表。  </p>
<h2 id="Hive面试题整理（二）"><a href="#Hive面试题整理（二）" class="headerlink" title="Hive面试题整理（二）"></a>Hive面试题整理（二）</h2><h3 id="Fetch抓取"><a href="#Fetch抓取" class="headerlink" title="Fetch抓取"></a>Fetch抓取</h3><p>&emsp; Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：SELECT * FROM employees;在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。<br>&emsp; 在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。  </p>
<h3 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h3><p>&emsp; 大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务时消耗可能会比实际job的执行时间要多的多。对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。<br>&emsp; 用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。  </p>
<h3 id="表的优化"><a href="#表的优化" class="headerlink" title="表的优化"></a><strong>表的优化</strong></h3><h3 id="小表、大表Join"><a href="#小表、大表Join" class="headerlink" title="小表、大表Join"></a>小表、大表Join</h3><p>&emsp; 将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用Group让小的维度表（1000条以下的记录条数）先进内存。在map端完成reduce。<br>&emsp; 实际测试发现：新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。  </p>
<h3 id="大表Join大表"><a href="#大表Join大表" class="headerlink" title="大表Join大表"></a>大表Join大表</h3><p>1）空KEY过滤<br>&emsp; 有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。例如key对应的字段为空。<br>2）空key转换<br>&emsp; 有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。  </p>
<h3 id="Group-By"><a href="#Group-By" class="headerlink" title="Group By"></a>Group By</h3><p>&emsp; 默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。<br>&emsp; 并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。<br>1）开启Map端聚合参数设置<br>&emsp; &emsp; （1）是否在Map端进行聚合，默认为True<br>&emsp; &emsp; &emsp; hive.map.aggr = true<br>&emsp; &emsp; （2）在Map端进行聚合操作的条目数目<br>&emsp; &emsp; &emsp; hive.groupby.mapaggr.checkinterval = 100000<br>&emsp; &emsp; （3）有数据倾斜的时候进行负载均衡（默认是false）<br>&emsp; &emsp; &emsp; hive.groupby.skewindata = true<br>&emsp; <strong>当选项设定为 true，生成的查询计划会有两个MR Job</strong>。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是<strong>相同的Group By Key有可能被分发到不同的Reduce中</strong>，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。  </p>
<h3 id="Count-Distinct-去重统计"><a href="#Count-Distinct-去重统计" class="headerlink" title="Count(Distinct) 去重统计"></a>Count(Distinct) 去重统计</h3><p>&emsp; 数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换  </p>
<h3 id="笛卡尔积"><a href="#笛卡尔积" class="headerlink" title="笛卡尔积"></a>笛卡尔积</h3><p>&emsp; 尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积  </p>
<h3 id="行列过滤"><a href="#行列过滤" class="headerlink" title="行列过滤"></a>行列过滤</h3><p>&emsp; 列处理：在SELECT中，只拿需要的列，如果有，尽量使用分区过滤，少用SELECT *。<br>&emsp; 行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤。  </p>
<h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a><strong>数据倾斜</strong></h3><h3 id="Map数"><a href="#Map数" class="headerlink" title="Map数"></a>Map数</h3><p>1）通常情况下，作业会通过input的目录产生一个或者多个map任务。<br>&emsp; 主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。<br>2）是不是map数越多越好？<br>&emsp; 答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。<br>3）是不是保证每个map处理接近128m的文件块，就高枕无忧了？<br>&emsp; 答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。<br>&emsp; 针对上面的问题2和3，我们需要采取两种方式来解决：即减少map数和增加map数；  </p>
<h3 id="小文件进行合并"><a href="#小文件进行合并" class="headerlink" title="小文件进行合并"></a>小文件进行合并</h3><p>&emsp; 在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。<br>&emsp; set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;  </p>
<h3 id="复杂文件增加Map数"><a href="#复杂文件增加Map数" class="headerlink" title="复杂文件增加Map数"></a>复杂文件增加Map数</h3><p>&emsp; 当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。<br>&emsp; 增加map的方法为：根据computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。  </p>
<h3 id="Reduce数"><a href="#Reduce数" class="headerlink" title="Reduce数"></a>Reduce数</h3><p>1）调整reduce个数方法一<br>&emsp; （1）每个Reduce处理的数据量默认是256MB<br>&emsp; &emsp; hive.exec.reducers.bytes.per.reducer=256000000<br>&emsp; （2）每个任务最大的reduce数，默认为1009<br>&emsp; &emsp; hive.exec.reducers.max=1009<br>&emsp; （3）计算reducer数的公式<br>&emsp; &emsp; N=min(参数2，总输入数据量/参数1)<br>2）调整reduce个数方法二<br>&emsp; 在hadoop的mapred-default.xml文件中修改<br>&emsp; 设置每个job的Reduce个数<br>&emsp; set mapreduce.job.reduces = 15;<br>3）reduce个数并不是越多越好<br>&emsp; （1）过多的启动和初始化reduce也会消耗时间和资源；<br>&emsp; （2）另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；<br>&emsp; 在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适。  </p>
<p><strong>==========================</strong>  </p>
<h3 id="并行执行"><a href="#并行执行" class="headerlink" title="并行执行"></a>并行执行</h3><p>&emsp; Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。<br>&emsp; 通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p>
<h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><h2 id="介绍下Kafka，Kafka的作用？Kafka的组件？适用场景？"><a href="#介绍下Kafka，Kafka的作用？Kafka的组件？适用场景？" class="headerlink" title="介绍下Kafka，Kafka的作用？Kafka的组件？适用场景？"></a>介绍下Kafka，Kafka的作用？Kafka的组件？适用场景？</h2><p>Kafka是一种分布式、高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据，主要应用于大数据实时处理领域。简单地说，Kafka就相比是一个邮箱，生产者是发送邮件的人，消费者是接收邮件的人，Kafka就是用来存东西的，只不过它提供了一些处理邮件的机制。</p>
<p><strong>1作用</strong></p>
<p>1）发布和订阅消息流</p>
<p>2）以容错的方式记录消息流，kafka以文件的方式来存储消息流</p>
<p>3）可以在消息发布的时候进行处理</p>
<p><strong>2、优势</strong></p>
<p>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒；</p>
<p>可扩展性：kafka集群支持热扩展；</p>
<p>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失；</p>
<p>容错性：允许集群中节点故障（若副本数量为n,则允许n-1个节点故障）；</p>
<p>高并发：支持数千个客户端同时读写。</p>
<p><strong>3、组件</strong></p>
<p align="center">
<img src="/images/bigDataGuideImgs/3.1kafka-介绍下Kafka01.png"/>  
<p align="center">
</p>
</p>  

<p><code>Topic</code> ：可以理解为一个队列，生产者和消费者面向的都是一个 topic；</p>
<p><code>Producer</code> ：消息生产者，就是向 kafka broker 发消息的客户端；</p>
<p><code>Consumer</code>：消息消费者，向 kafka broker 取消息的客户端；</p>
<p><code>Broker</code> ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个 topic。</p>
<p><strong>4、使用场景</strong></p>
<p>1）在系统或应用程序之间构建可靠的用于传输实时数据的管道，消息队列功能</p>
<p>2）构建实时的流数据处理程序来变换或处理数据流，数据处理功能</p>
<p>通俗一点来说</p>
<p>日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer；</p>
<p>消息系统：解耦生产者和消费者、缓存消息等；</p>
<p>用户活动跟踪：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后消费者通过订阅这些topic来做实时的监控分析，亦可保存到数据库；</p>
<p>运营指标：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；</p>
<p>流式处理：比如Spark streaming和Flink。</p>
<h2 id="Kafka面试题总结（一）"><a href="#Kafka面试题总结（一）" class="headerlink" title="Kafka面试题总结（一）"></a>Kafka面试题总结（一）</h2><h3 id="Kafka-都有哪些特点？"><a href="#Kafka-都有哪些特点？" class="headerlink" title="Kafka 都有哪些特点？"></a>Kafka 都有哪些特点？</h3><p>&emsp; 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。<br>&emsp; 可扩展性：kafka集群支持热扩展<br>&emsp; 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失<br>&emsp; 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）<br>&emsp; 高并发：支持数千个客户端同时读写  </p>
<h3 id="请简述下你在哪些场景下会选择-Kafka？"><a href="#请简述下你在哪些场景下会选择-Kafka？" class="headerlink" title="请简述下你在哪些场景下会选择 Kafka？"></a>请简述下你在哪些场景下会选择 Kafka？</h3><p>&emsp; 日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、HBase、Solr等。<br>&emsp; 消息系统：解耦和生产者和消费者、缓存消息等。<br>&emsp; 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。<br>&emsp; 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。<br>&emsp; 流式处理：比如spark streaming和 Flink  </p>
<h3 id="Kafka-的设计架构？"><a href="#Kafka-的设计架构？" class="headerlink" title="Kafka 的设计架构？"></a>Kafka 的设计架构？</h3><p>简单架构如下：  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/3.2.3Kafka简单架构.jpg"/>  
<p align="center">
</p>
</p>  



<p>详细架构如下：  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/3.2.3Kafka详细架构.jpg"/>  
<p align="center">
</p>
</p>  


<p>Kafka 架构分为以下几个部分：<br>&emsp; Producer：消息生产者，就是向 kafka broker 发消息的客户端。<br>&emsp; Consumer：消息消费者，向 kafka broker 取消息的客户端。<br>&emsp; Topic：可以理解为一个队列，一个 Topic 又分为一个或多个分区。<br>&emsp; Consumer Group：这是 kafka 用来实现一个 topic 消息的广播（发给所有的 consumer）和单播（发给任意一个 consumer）的手段。一个 topic 可以有多个 Consumer Group。<br>&emsp; Broker：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。<br>&emsp; Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker上，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。将消息发给 consumer，kafka 只保证按一个 partition 中的消息的顺序，不保证一个 topic 的整体（多个 partition 间）的顺序。<br>&emsp; Offset：kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是 00000000000.kafka。  </p>
<h3 id="Kafka-分区的目的？"><a href="#Kafka-分区的目的？" class="headerlink" title="Kafka 分区的目的？"></a>Kafka 分区的目的？</h3><p>&emsp; 分区对于 Kafka 集群的好处是：实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率。  </p>
<h3 id="Kafka-是如何做到消息的有序性？"><a href="#Kafka-是如何做到消息的有序性？" class="headerlink" title="Kafka 是如何做到消息的有序性？"></a>Kafka 是如何做到消息的有序性？</h3><p>&emsp; kafka 中的每个 partition 中的消息在写入时都是有序的，而且单独一个 partition 只能由一个消费者去消费，可以在里面保证消息的顺序性。但是分区之间的消息是不保证有序的。  </p>
<h3 id="Kafka-的高可靠性是怎么实现的？"><a href="#Kafka-的高可靠性是怎么实现的？" class="headerlink" title="Kafka 的高可靠性是怎么实现的？"></a>Kafka 的高可靠性是怎么实现的？</h3><p><strong>可回答：<br>&emsp; Kafka 在什么情况下会出现消息丢失？</strong><br>1）<strong>数据可靠性（可回答 怎么尽可能保证 Kafka 的可靠性？）</strong><br>&emsp; Kafka 作为一个商业级消息中间件，消息可靠性的重要性可想而知。本文从 Producter 往 Broker 发送消息、Topic 分区副本以及 Leader 选举几个角度介绍数据的可靠性。<br>&emsp; <strong>Topic分区副本</strong><br>&emsp; 在 Kafka 0.8.0 之前，Kafka 是没有副本的概念的，那时候人们只会用 Kafka 存储一些不重要的数据，因为没有副本，数据很可能会丢失。但是随着业务的发展，支持副本的功能越来越强烈，所以为了保证数据的可靠性，Kafka 从 0.8.0 版本开始引入了分区副本（详情请参见 KAFKA-50）。也就是说每个分区可以人为的配置几个副本（比如创建主题的时候指定 replication-factor，也可以在 Broker 级别进行配置 default.replication.factor），一般会设置为3。<br>&emsp; Kafka 可以保证单个分区里的事件是有序的，分区可以在线（可用），也可以离线（不可用）。在众多的分区副本里面有一个副本是 Leader，其余的副本是 follower，所有的读写操作都是经过 Leader 进行的，同时 follower 会定期地去 leader 上的复制数据。当 Leader 挂了的时候，其中一个 follower 会重新成为新的 Leader。通过分区副本，引入了数据冗余，同时也提供了 Kafka 的数据可靠性。<br>&emsp; <strong>Kafka 的分区多副本架构是 Kafka 可靠性保证的核心，把消息写入多个副本可以使 Kafka 在发生崩溃时仍能保证消息的持久性</strong>。<br>&emsp; <strong>Producer 往 Broker 发送消息</strong><br>&emsp; 如果我们要往 Kafka 对应的主题发送消息，我们需要通过 Producer 完成。前面我们讲过 Kafka 主题对应了多个分区，每个分区下面又对应了多个副本；为了让用户设置数据可靠性， Kafka 在 Producer 里面提供了消息确认机制。也就是说我们可以通过配置来决定消息发送到对应分区的几个副本才算消息发送成功。可以在定义 Producer 时通过 acks 参数指定（在 0.8.2.X 版本之前是通过 request.required.acks 参数设置的）。<br>&emsp; 这个参数支持以下三种值：<br>&emsp; acks = 0：意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入Kafka。在这种情况下还是有可能发生错误，比如发送的对象无能被序列化或者网卡发生故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。在 acks=0 模式下的运行速度是非常快的（这就是为什么很多基准测试都是基于这个模式），你可以得到惊人的吞吐量和带宽利用率，不过如果选择了这种模式， 一定会丢失一些消息。<br>&emsp; acks = 1：意味若 Leader 在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。在这个模式下，如果发生正常的 Leader 选举，生产者会在选举时收到一个 LeaderNotAvailableException 异常，如果生产者能恰当地处理这个错误，它会重试发送悄息，最终消息会安全到达新的 Leader 那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入 Leader，但在消息被复制到 follower 副本之前 Leader发生崩溃。<br>&emsp; acks = all（这个和 request.required.acks = -1 含义一样）：意味着 Leader 在返回确认或错误响应之前，会等待所有同步副本都收到悄息。如果和 min.insync.replicas 参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到悄息，生产者会一直重试直到消息被成功提交。不过这也是最慢的做法，因为生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。<br>&emsp; 根据实际的应用场景，我们设置不同的 acks，以此保证数据的可靠性。<br>&emsp; 另外，Producer 发送消息还可以选择同步（默认，通过 producer.type=sync 配置） 或者异步（producer.type=async）模式。如果设置成异步，虽然会极大的提高消息发送的性能，但是这样会增加丢失数据的风险。如果需要确保消息的可靠性，必须将 producer.type 设置为 sync。<br>&emsp; <strong>Leader 选举</strong><br>&emsp; 在介绍 Leader 选举之前，让我们先来了解一下 ISR（in-sync replicas）列表。每个分区的 leader 会维护一个 ISR 列表，ISR 列表里面就是 follower 副本的 Borker 编号，只有跟得上 Leader 的 follower 副本才能加入到 ISR 里面，这个是通过 replica.lag.time.max.ms 参数配置的。只有 ISR 里的成员才有被选为 leader 的可能。<br>2）<strong>数据一致性（可回答 Kafka数据一致性原理？）</strong><br>&emsp; 这里介绍的数据一致性主要是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。那么 Kafka 是如何实现的呢？  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/3.2.6数据一致性.jpg"/>  
<p align="center">
</p>
</p>  

<p>&emsp; 假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，对应于上图的副本2，这个很类似于木桶原理。<br>&emsp; 这样做的原因是还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。<br>&emsp; 当然，引入了 High Water Mark 机制，会导致 Broker 间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长（因为我们会先等待消息复制完毕）。延迟时间可以通过参数 replica.lag.time.max.ms 参数配置，它指定了副本在复制消息时可被允许的最大延迟时间。  </p>
<h3 id="ISR、OSR、AR-是什么？"><a href="#ISR、OSR、AR-是什么？" class="headerlink" title="ISR、OSR、AR 是什么？"></a>ISR、OSR、AR 是什么？</h3><p>&emsp; ISR：In-Sync Replicas 副本同步队列<br>&emsp; OSR：Out-of-Sync Replicas<br>&emsp; AR：Assigned Replicas 所有副本<br>&emsp; ISR是由leader维护，follower从leader同步数据有一些延迟（具体可以参见 图文了解 Kafka 的副本复制机制），超过相应的阈值会把 follower 剔除出 ISR, 存入OSR（Out-of-Sync Replicas ）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。  </p>
<h3 id="LEO、HW、LSO、LW等分别代表什么？"><a href="#LEO、HW、LSO、LW等分别代表什么？" class="headerlink" title="LEO、HW、LSO、LW等分别代表什么？"></a>LEO、HW、LSO、LW等分别代表什么？</h3><p>&emsp; LEO：是 LogEndOffset 的简称，代表当前日志文件中下一条<br>&emsp; HW：水位或水印（watermark）一词，也可称为高水位(high watermark)，通常被用在流式处理领域（比如Apache Flink、Apache Spark等），以表征元素或事件在基于时间层面上的进度。在Kafka中，水位的概念反而与时间无关，而是与位置信息相关。严格来说，它表示的就是位置信息，即位移（offset）。取 partition 对应的 ISR中 最小的 LEO 作为 HW，consumer 最多只能消费到 HW 所在的位置上一条信息。<br>&emsp; LSO：是 LastStableOffset 的简称，对未完成的事务而言，LSO 的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同 HW 相同<br>&emsp; LW：Low Watermark 低水位, 代表 AR 集合中最小的 logStartOffset 值。  </p>
<h3 id="数据传输的事务有几种？"><a href="#数据传输的事务有几种？" class="headerlink" title="数据传输的事务有几种？"></a>数据传输的事务有几种？</h3><p>&emsp; 数据传输的事务定义通常有以下三种级别：<br>&emsp; 最多一次：消息不会被重复发送，最多被传输一次，但也有可能一次不传输<br>&emsp; 最少一次：消息不会被漏发送，最少被传输一次，但也有可能被重复传输<br>&emsp; 精确的一次（Exactly once）：不会漏传输也不会重复传输，每个消息都传输被接收  </p>
<h3 id="Kafka-消费者是否可以消费指定分区消息？"><a href="#Kafka-消费者是否可以消费指定分区消息？" class="headerlink" title="Kafka 消费者是否可以消费指定分区消息？"></a>Kafka 消费者是否可以消费指定分区消息？</h3><p>&emsp; Kafa consumer消费消息时，向broker发出fetch请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的。  </p>
<h3 id="Kafka消息是采用Pull模式，还是Push模式？"><a href="#Kafka消息是采用Pull模式，还是Push模式？" class="headerlink" title="Kafka消息是采用Pull模式，还是Push模式？"></a>Kafka消息是采用Pull模式，还是Push模式？</h3><p>&emsp; Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push。在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。<br>&emsp; 一些消息系统比如Scribe和Apache Flume采用了push模式，将消息推送到下游的consumer。这样做有好处也有坏处：由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。消息系统都致力于让consumer以最大的速率最快速的消费消息，但不幸的是，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。最终Kafka还是选取了传统的pull模式。<br>&emsp; Pull模式的另外一个好处是consumer可以自主决定是否批量的从broker拉取数据。Push模式必须在不知道下游consumer消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送。如果为了避免consumer崩溃而采用较低的推送速率，将可能导致一次只推送较少的消息而造成浪费。Pull模式下，consumer就可以根据自己的消费能力去决定这些策略。 Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到t达。为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发送）  </p>
<h3 id="Kafka-高效文件存储设计特点？"><a href="#Kafka-高效文件存储设计特点？" class="headerlink" title="Kafka 高效文件存储设计特点？"></a>Kafka 高效文件存储设计特点？</h3><p>&emsp; 1）Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。<br>&emsp; 2）通过索引信息可以快速定位message和确定response的最大大小。<br>&emsp; 3）通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。<br>&emsp; 4）通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。  </p>
<h3 id="Kafka创建Topic时如何将分区放置到不同的Broker中？"><a href="#Kafka创建Topic时如何将分区放置到不同的Broker中？" class="headerlink" title="Kafka创建Topic时如何将分区放置到不同的Broker中？"></a>Kafka创建Topic时如何将分区放置到不同的Broker中？</h3><p>&emsp; 1）副本因子不能大于 Broker 的个数；<br>&emsp; 2）第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；<br>&emsp; 3）其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；<br>&emsp; 4）剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的；  </p>
<h3 id="Kafka新建的分区会在哪个目录下创建？"><a href="#Kafka新建的分区会在哪个目录下创建？" class="headerlink" title="Kafka新建的分区会在哪个目录下创建？"></a>Kafka新建的分区会在哪个目录下创建？</h3><p>&emsp; 我们知道，在启动 Kafka 集群之前，我们需要配置好 log.dirs 参数，其值是 Kafka 数据的存放目录，这个参数可以配置多个目录，目录之间使用逗号分隔，通常这些目录是分布在不同的磁盘上用于提高读写性能。当然我们也可以配置 log.dir 参数，含义一样。只需要设置其中一个即可。<br>&emsp; 如果 log.dirs 参数只配置了一个目录，那么分配到各个 Broker 上的分区肯定只能在这个目录下创建文件夹用于存放数据。<br>&emsp; 但是如果 log.dirs 参数配置了多个目录，那么 Kafka 会在哪个文件夹中创建分区目录呢？答案是：Kafka 会在含有分区目录最少的文件夹中创建新的分区目录，分区目录名为 Topic名+分区ID。注意，是分区文件夹总数最少的目录，而不是磁盘使用量最少的目录！也就是说，如果你给 log.dirs 参数新增了一个新的磁盘，新的分区目录肯定是先在这个新的磁盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止。  </p>
<h3 id="谈一谈-Kafka-的再均衡"><a href="#谈一谈-Kafka-的再均衡" class="headerlink" title="谈一谈 Kafka 的再均衡"></a>谈一谈 Kafka 的再均衡</h3><p>&emsp; 在Kafka中，当有新消费者加入或者订阅的topic数发生变化时，会触发Rebalance(再均衡：在同一个消费者组当中，分区的所有权从一个消费者转移到另外一个消费者)机制，Rebalance顾名思义就是重新均衡消费者消费。Rebalance的过程如下：<br>&emsp; 第一步：所有成员都向coordinator发送请求，请求入组。一旦所有成员都发送了请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader。<br>&emsp; 第二步：leader开始分配消费方案，指明具体哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案发给coordinator。coordinator接收到分配方案之后会把方案发给各个consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。<br>&emsp; 所以对于Rebalance来说，Coordinator起着至关重要的作用。  </p>
<h3 id="Kafka分区分配策略"><a href="#Kafka分区分配策略" class="headerlink" title="Kafka分区分配策略"></a>Kafka分区分配策略</h3><p align="center">
<img src="/images/bigDataGuideImgs/3.2.16Kafka分区分配策略.png"/>  
<p align="center">
</p>
</p>  

<p>&emsp; 在 Kafka 内部存在两种默认的分区分配策略：Range 和 RoundRobin。当以下事件发生时，Kafka 将会进行一次分区分配：<br>&emsp; 1）同一个 Consumer Group 内新增消费者<br>&emsp; 2）消费者离开当前所属的Consumer Group，包括shuts down 或 crashes<br>&emsp; 3）订阅的主题新增分区<br>&emsp; 将分区的所有权从一个消费者移到另一个消费者称为重新平衡（rebalance），如何rebalance就涉及到下面提到的分区分配策略。下面我们将详细介绍 Kafka 内置的两种分区分配策略。本文假设我们有个名为 T1 的主题，其包含了10个分区，然后我们有两个消费者（C1，C2）来消费这10个分区里面的数据，而且 C1 的 num.streams = 1，C2 的 num.streams = 2。<br>&emsp; <strong>Range strategy</strong><br>&emsp; Range策略是对每个主题而言的，首先对同一个主题里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。在我们的例子里面，排完序的分区将会是0, 1, 2, 3, 4, 5, 6, 7, 8, 9；消费者线程排完序将会是C1-0, C2-0, C2-1。然后将partitions的个数除于消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。<br>&emsp; 在我们的例子里面，我们有10个分区，3个消费者线程，10 / 3 = 3，而且除不尽，那么消费者线程 C1-0 将会多消费一个分区，所以最后分区分配的结果看起来是这样的：<br>&emsp; C1-0 将消费 0, 1, 2, 3 分区<br>&emsp; C2-0 将消费 4, 5, 6 分区<br>&emsp; C2-1 将消费 7, 8, 9 分区<br>&emsp; 假如我们有11个分区，那么最后分区分配的结果看起来是这样的：<br>&emsp; C1-0 将消费 0, 1, 2, 3 分区<br>&emsp; C2-0 将消费 4, 5, 6, 7 分区<br>&emsp; C2-1 将消费 8, 9, 10 分区<br>&emsp; 假如我们有2个主题(T1和T2)，分别有10个分区，那么最后分区分配的结果看起来是这样的：<br>&emsp; C1-0 将消费 T1主题的 0, 1, 2, 3 分区以及 T2主题的 0, 1, 2, 3分区<br>&emsp; C2-0 将消费 T1主题的 4, 5, 6 分区以及 T2主题的 4, 5, 6分区<br>&emsp; C2-1 将消费 T1主题的 7, 8, 9 分区以及 T2主题的 7, 8, 9分区<br>&emsp; 可以看出，C1-0 消费者线程比其他消费者线程多消费了2个分区，这就是Range strategy的一个很明显的弊端。<br>&emsp; <strong>RoundRobin strategy</strong><br>&emsp; 使用RoundRobin策略有两个前提条件必须满足：<br>&emsp; 同一个Consumer Group里面的所有消费者的num.streams必须相等；<br>&emsp; 每个消费者订阅的主题必须相同。<br>&emsp; 所以这里假设前面提到的2个消费者的num.streams = 2。RoundRobin策略的工作原理：将所有主题的分区组成 TopicAndPartition 列表，然后对 TopicAndPartition 列表按照 hashCode 进行排序，这里文字可能说不清，看下面的代码应该会明白：  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> allTopicPartitions = ctx.partitionsForTopic.flatMap &#123; <span class="keyword">case</span>(topic, partitions) =&gt;</span><br><span class="line">  info(<span class="string">&quot;Consumer %s rebalancing the following partitions for topic %s: %s&quot;</span></span><br><span class="line">       .format(ctx.consumerId, topic, partitions))</span><br><span class="line">  partitions.map(partition =&gt; &#123;</span><br><span class="line">   <span class="type">TopicAndPartition</span>(topic, partition)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;.toSeq.sortWith((topicPartition1, topicPartition2) =&gt; &#123;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Randomize the order by taking the hashcode to reduce the likelihood of all partitions of a given topic ending</span></span><br><span class="line"><span class="comment">   * up on one consumer (if it has a high enough stream count).</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  topicPartition1.toString.hashCode &lt; topicPartition2.toString.hashCode</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>&emsp; 最后按照round-robin风格将分区分别分配给不同的消费者线程。<br>&emsp; 在我们的例子里面，假如按照 hashCode 排序完的topic-partitions组依次为T1-5, T1-3, T1-0, T1-8, T1-2, T1-1, T1-4, T1-7, T1-6, T1-9，我们的消费者线程排序为C1-0, C1-1, C2-0, C2-1，最后分区分配的结果为：<br>&emsp; C1-0 将消费 T1-5, T1-2, T1-6 分区；<br>&emsp; C1-1 将消费 T1-3, T1-1, T1-9 分区；<br>&emsp; C2-0 将消费 T1-0, T1-4 分区；<br>&emsp; C2-1 将消费 T1-8, T1-7 分区。<br>&emsp; 多个主题的分区分配和单个主题类似。  </p>
<h3 id="Kafka-是如何实现高吞吐率的？"><a href="#Kafka-是如何实现高吞吐率的？" class="headerlink" title="Kafka 是如何实现高吞吐率的？"></a>Kafka 是如何实现高吞吐率的？</h3><p>&emsp; Kafka是分布式消息系统，需要处理海量的消息，Kafka的设计是把所有的消息都写入速度低容量大的硬盘，以此来换取更强的存储能力，但实际上，使用硬盘并没有带来过多的性能损失。kafka主要使用了以下几个方式实现了超高的吞吐率：<br>&emsp; 1）顺序读写<br>&emsp; 2）零拷贝<br>&emsp; 3）文件分段<br>&emsp; 4）批量发送<br>&emsp; 5）数据压缩  </p>
<h3 id="Kafka-缺点？"><a href="#Kafka-缺点？" class="headerlink" title="Kafka 缺点？"></a>Kafka 缺点？</h3><p>&emsp; 1）由于是批量发送，数据并非真正的实时；<br>&emsp; 2）对于mqtt协议不支持；<br>&emsp; 3）不支持物联网传感数据直接接入；<br>&emsp; 4）仅支持统一分区内消息有序，无法实现全局消息有序；<br>&emsp; 5）监控不完善，需要安装插件；<br>&emsp; 6）依赖zookeeper进行元数据管理。  </p>
<h3 id="Kafka-新旧消费者的区别？"><a href="#Kafka-新旧消费者的区别？" class="headerlink" title="Kafka 新旧消费者的区别？"></a>Kafka 新旧消费者的区别？</h3><p>&emsp; 旧的 Kafka 消费者 API 主要包括：SimpleConsumer（简单消费者） 和 ZookeeperConsumerConnectir（高级消费者）。SimpleConsumer 名字看起来是简单消费者，但是其实用起来很不简单，可以使用它从特定的分区和偏移量开始读取消息。高级消费者和现在新的消费者有点像，有消费者群组，有分区再均衡，不过它使用 ZK 来管理消费者群组，并不具备偏移量和再均衡的可操控性。<br>&emsp; 现在的消费者同时支持以上两种行为，所以为啥还用旧消费者 API 呢？  </p>
<h3 id="Kafka-分区数可以增加或减少吗？为什么？"><a href="#Kafka-分区数可以增加或减少吗？为什么？" class="headerlink" title="Kafka 分区数可以增加或减少吗？为什么？"></a>Kafka 分区数可以增加或减少吗？为什么？</h3><p>&emsp; 我们可以使用 bin/kafka-topics.sh 命令对 Kafka 增加 Kafka 的分区数据，但是 Kafka 不支持减少分区数。 Kafka 分区数据不支持减少是由很多原因的，比如减少的分区其数据放到哪里去？是删除，还是保留？删除的话，那么这些没消费的消息不就丢了。如果保留这些消息如何放到其他分区里面？追加到其他分区后面的话那么就破坏了 Kafka 单个分区的有序性。如果要保证删除分区数据插入到其他分区保证有序性，那么实现起来逻辑就会非常复杂。  </p>
<h2 id="Kafka面试题整理（二）"><a href="#Kafka面试题整理（二）" class="headerlink" title="Kafka面试题整理（二）"></a>Kafka面试题整理（二）</h2><h3 id="请说明什么是Apache-Kafka？"><a href="#请说明什么是Apache-Kafka？" class="headerlink" title="请说明什么是Apache Kafka？"></a>请说明什么是Apache Kafka？</h3><p>&emsp; Apache Kafka是由Apache开发的一种发布订阅消息系统，它是一个分布式的、分区的和重复的日志服务。  </p>
<h3 id="请说明什么是传统的消息传递方法？"><a href="#请说明什么是传统的消息传递方法？" class="headerlink" title="请说明什么是传统的消息传递方法？"></a>请说明什么是传统的消息传递方法？</h3><p>&emsp; 传统的消息传递方法包括两种：<br>&emsp; &emsp; 队列：在队列中，一组用户可以从服务器中读取消息，每条消息都发送给其中一个人。<br>&emsp; &emsp; 发布-订阅：在这个模型中，消息被广播给所有的用户。  </p>
<h3 id="请说明Kafka相对于传统的消息传递方法有什么优势？"><a href="#请说明Kafka相对于传统的消息传递方法有什么优势？" class="headerlink" title="请说明Kafka相对于传统的消息传递方法有什么优势？"></a>请说明Kafka相对于传统的消息传递方法有什么优势？</h3><p>&emsp; 高性能：单一的Kafka代理可以处理成千上万的客户端，每秒处理数兆字节的读写操作，Kafka性能远超过传统的ActiveMQ、RabbitMQ等，而且Kafka支持Batch操作；<br>&emsp; 可扩展：Kafka集群可以透明的扩展，增加新的服务器进集群；<br>&emsp; 容错性： Kafka每个Partition数据会复制到几台服务器，当某个Broker失效时，Zookeeper将通知生产者和消费者从而使用其他的Broker。  </p>
<h3 id="在Kafka中broker的意义是什么？"><a href="#在Kafka中broker的意义是什么？" class="headerlink" title="在Kafka中broker的意义是什么？"></a>在Kafka中broker的意义是什么？</h3><p>&emsp; 在Kafka集群中，broker指Kafka服务器。<br>&emsp; 术语解析：  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/3.3.4Kafka中broker的意义.png"/>  
<p align="center">
</p>
</p>  



<h3 id="Kafka服务器能接收到的最大信息是多少？"><a href="#Kafka服务器能接收到的最大信息是多少？" class="headerlink" title="Kafka服务器能接收到的最大信息是多少？"></a>Kafka服务器能接收到的最大信息是多少？</h3><p>&emsp; Kafka服务器可以接收到的消息的最大大小是1000000字节。  </p>
<h3 id="Kafka中的ZooKeeper是什么？Kafka是否可以脱离ZooKeeper独立运行？"><a href="#Kafka中的ZooKeeper是什么？Kafka是否可以脱离ZooKeeper独立运行？" class="headerlink" title="Kafka中的ZooKeeper是什么？Kafka是否可以脱离ZooKeeper独立运行？"></a>Kafka中的ZooKeeper是什么？Kafka是否可以脱离ZooKeeper独立运行？</h3><p>&emsp; Zookeeper是一个开放源码的、高性能的协调服务，它用于Kafka的分布式应用。<br>&emsp; 不可以，不可能越过Zookeeper直接联系Kafka broker，一旦Zookeeper停止工作，它就不能服务客户端请求。<br>&emsp; Zookeeper主要用于在集群中不同节点之间进行通信，在Kafka中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取，除此之外，它还执行其他活动，如: leader检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态等等。  </p>
<h3 id="解释Kafka的用户如何消费信息？"><a href="#解释Kafka的用户如何消费信息？" class="headerlink" title="解释Kafka的用户如何消费信息？"></a>解释Kafka的用户如何消费信息？</h3><p>&emsp; 在Kafka中传递消息是通过使用sendfile API完成的。它支持将字节Socket转移到磁盘，通过内核空间保存副本，并在内核用户之间调用内核。  </p>
<h3 id="解释如何提高远程用户的吞吐量？"><a href="#解释如何提高远程用户的吞吐量？" class="headerlink" title="解释如何提高远程用户的吞吐量？"></a>解释如何提高远程用户的吞吐量？</h3><p>&emsp; 如果用户位于与broker不同的数据中心，则可能需要调优Socket缓冲区大小，以对长网络延迟进行摊销。  </p>
<h3 id="解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息？"><a href="#解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息？" class="headerlink" title="解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息？"></a>解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息？</h3><p>&emsp; 在数据中，为了精确地获得Kafka的消息，你必须遵循两件事：<strong>在数据消耗期间避免重复，在数据生产过程中避免重复</strong>。<br>&emsp; 这里有两种方法，可以在数据生成时准确地获得一个语义:<br>&emsp; 每个分区使用一个单独的写入器，每当你发现一个网络错误，检查该分区中的最后一条消息，以查看您的最后一次写入是否成功。<br>&emsp; 在消息中包含一个主键(UUID或其他)，并在用户中进行反复制。  </p>
<h3 id="解释如何减少ISR中的扰动？broker什么时候离开ISR？（☆☆☆☆☆）"><a href="#解释如何减少ISR中的扰动？broker什么时候离开ISR？（☆☆☆☆☆）" class="headerlink" title="解释如何减少ISR中的扰动？broker什么时候离开ISR？（☆☆☆☆☆）"></a>解释如何减少ISR中的扰动？broker什么时候离开ISR？（☆☆☆☆☆）</h3><p>&emsp; ISR是一组与leaders完全同步的消息副本，也就是说ISR中包含了所有提交的消息。ISR应该总是包含所有的副本，直到出现真正的故障。如果一个副本从leader中脱离出来，将会从ISR中删除。  </p>
<h3 id="Kafka为什么需要复制？"><a href="#Kafka为什么需要复制？" class="headerlink" title="Kafka为什么需要复制？"></a>Kafka为什么需要复制？</h3><p>&emsp; Kafka的信息复制确保了任何已发布的消息不会丢失，并且可以在机器错误、程序错误或更常见些的软件升级中使用。  </p>
<h3 id="如果副本在ISR中停留了很长时间表明什么？"><a href="#如果副本在ISR中停留了很长时间表明什么？" class="headerlink" title="如果副本在ISR中停留了很长时间表明什么？"></a>如果副本在ISR中停留了很长时间表明什么？</h3><p>&emsp; 如果一个副本在ISR中保留了很长一段时间，那么它就表明，跟踪器无法像在leader收集数据那样快速地获取数据。  </p>
<h3 id="请说明如果首选的副本不在ISR中会发生什么？"><a href="#请说明如果首选的副本不在ISR中会发生什么？" class="headerlink" title="请说明如果首选的副本不在ISR中会发生什么？"></a>请说明如果首选的副本不在ISR中会发生什么？</h3><p>&emsp; 如果首选的副本不在ISR中，控制器将无法将leadership转移到首选的副本。  </p>
<h3 id="Kafka有可能在生产后发生消息偏移吗？"><a href="#Kafka有可能在生产后发生消息偏移吗？" class="headerlink" title="Kafka有可能在生产后发生消息偏移吗？"></a>Kafka有可能在生产后发生消息偏移吗？</h3><p>&emsp; 在大多数队列系统中，作为生产者的类无法做到这一点，它的作用是触发并忘记消息。broker将完成剩下的工作，比如使用id进行适当的元数据处理、偏移量等。<br>&emsp; 作为消息的用户，你可以从Kafka broker中获得补偿。如果你注视SimpleConsumer类，你会注意到它会获取包括偏移量作为列表的MultiFetchResponse对象。此外，当你对Kafka消息进行迭代时，你会拥有包括偏移量和消息发送的MessageAndOffset对象。  </p>
<h3 id="请说明Kafka-的消息投递保证（delivery-guarantee）机制以及如何实现？（☆☆☆☆☆）"><a href="#请说明Kafka-的消息投递保证（delivery-guarantee）机制以及如何实现？（☆☆☆☆☆）" class="headerlink" title="请说明Kafka 的消息投递保证（delivery guarantee）机制以及如何实现？（☆☆☆☆☆）"></a>请说明Kafka 的消息投递保证（delivery guarantee）机制以及如何实现？（☆☆☆☆☆）</h3><p>&emsp; Kafka支持三种消息投递语义：<br>&emsp; ① At most once 消息可能会丢，但绝不会重复传递<br>&emsp; ② At least one 消息绝不会丢，但可能会重复传递<br>&emsp; ③ Exactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户想要的<br>&emsp; consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中存下该consumer在该partition下读取的消息的offset，该consumer下一次再读该partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。<br>&emsp; 可以将consumer设置为autocommit，即consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了Exactly once。但实际上实际使用中consumer并非读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。<br>&emsp; 读完消息先commit再处理消息。这种模式下，如果consumer在commit后还没来得及处理消息就crash了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于At most once。<br>&emsp; 读完消息先处理再commit消费状态(保存offset)。这种模式下，如果在处理完消息之后commit之前Consumer crash了，下次重新开始工作时还会处理刚刚未commit的消息，实际上该消息已经被处理过了，这就对应于At least once。<br>&emsp; 如果一定要做到Exactly once，就需要协调offset和实际操作的输出。经典的做法是引入两阶段提交，但由于许多输出系统不支持两阶段提交，更为通用的方式是将offset和操作输入存在同一个地方。比如，consumer拿到数据后可能把数据放到HDFS，如果把最新的offset和数据本身一起写到HDFS，那就可以保证数据的输出和offset的更新要么都完成，要么都不完成，间接实现Exactly once。（目前就high level API而言，offset是存于Zookeeper中的，无法存于HDFS，而low level API的offset是由自己去维护的，可以将之存于HDFS中）。<br>&emsp; 总之，Kafka默认保证At least once，并且允许通过设置producer异步提交来实现At most once，而Exactly once要求与目标存储系统协作，Kafka提供的offset可以较为容易地实现这种方式。  </p>
<h3 id="如何保证Kafka的消息有序（☆☆☆☆☆）"><a href="#如何保证Kafka的消息有序（☆☆☆☆☆）" class="headerlink" title="如何保证Kafka的消息有序（☆☆☆☆☆）"></a>如何保证Kafka的消息有序（☆☆☆☆☆）</h3><p>&emsp; Kafka对于消息的重复、丢失、错误以及顺序没有严格的要求。<br>&emsp; Kafka只能保证一个partition中的消息被某个consumer消费时是顺序的，事实上，从Topic角度来说，当有多个partition时，消息仍然不是全局有序的。  </p>
<h3 id="kafka数据丢失问题-及如何保证？"><a href="#kafka数据丢失问题-及如何保证？" class="headerlink" title="kafka数据丢失问题,及如何保证？"></a>kafka数据丢失问题,及如何保证？</h3><p>1）数据丢失：<br>&emsp; acks=1的时候(只保证写入leader成功)，如果刚好leader挂了。数据会丢失。<br>&emsp; acks=0的时候，使用异步模式的时候，该模式下kafka无法保证消息，有可能会丢。<br>2）brocker如何保证不丢失：<br>&emsp; acks=all : 所有副本都写入成功并确认。<br>&emsp; retries = 一个合理值。<br>&emsp; min.insync.replicas=2  消息至少要被写入到这么多副本才算成功。<br>&emsp; unclean.leader.election.enable=false 关闭unclean leader选举，即不允许非ISR中的副本被选举为leader，以避免数据丢失。<br>3）Consumer如何保证不丢失<br>&emsp; 如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失。<br>&emsp; enabel.auto.commit=false关闭自动提交offset<br>&emsp; 处理完数据之后手动提交。  </p>
<h3 id="kafka的balance是怎么做的？"><a href="#kafka的balance是怎么做的？" class="headerlink" title="kafka的balance是怎么做的？"></a>kafka的balance是怎么做的？</h3><p>&emsp; 生产者将数据发布到他们选择的主题。生产者可以选择在主题中分配哪个分区的消息。这可以通过循环的方式来完成，只是为了平衡负载，或者可以根据一些语义分区功能（比如消息中的一些键）来完成。更多关于分区在一秒钟内的使用。  </p>
<h3 id="kafka的消费者方式？"><a href="#kafka的消费者方式？" class="headerlink" title="kafka的消费者方式？"></a>kafka的消费者方式？</h3><p>&emsp; consumer采用pull（拉）模式从broker中读取数据。<br>&emsp; push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。<br>&emsp; 对于Kafka而言，pull模式更合适，它可简化broker的设计，consumer可自主控制消费消息的速率，同时consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。<br>&emsp; pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直等待数据到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞。  </p>
<h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h2 id="HBase架构"><a href="#HBase架构" class="headerlink" title="HBase架构"></a>HBase架构</h2><p><img src="/images/bigDataGuideImgs/4.1HBase架构.png"></p>
<p>从Hbase的架构图上可以看出，Hbase中的存储包括HMaster、HRegionSever、HRegion、HLog、Store、MemStore、StoreFile、HFile等。</p>
<p>Hbase中的每张表都通过键按照一定的范围被分割成多个子表（HRegion），默认一个HRegion超过256M就要被分割成两个，这个过程由HRegionServer管理,而HRegion的分配由HMaster管理。</p>
<p>1）HMaster的作用：</p>
<p>为HRegionServer分配HRegion</p>
<p>负责HRegionServer的负载均衡</p>
<p>发现失效的HRegionServer并重新分配</p>
<p>HDFS上的垃圾文件回收</p>
<p>处理Schema更新请求</p>
<p>2）HRegionServer的作用：</p>
<p>维护HMaster分配给它的HRegion，处理对这些HRegion的IO请求</p>
<p>负责切分正在运行过程中变得过大的HRegion</p>
<p>通过架构可以得知，Client访问Hbase上的数据并不需要HMaster参与，寻址访问ZooKeeper和HRegionServer，数据读写访问HRegionServer，HMaster仅仅维护Table和Region的元数据信息，Table的元数据信息保存在ZooKeeper上，负载很低。HRegionServer存取一个子表时，会创建一个HRegion对象，然后对表的每个列簇创建一个Store对象，每个Store都会有一个MemStore和0或多个StoreFile与之对应，每个StoreFile都会对应一个HFile，HFile就是实际的存储文件。因此，一个HRegion有多少列簇就有多少个Store。</p>
<p>一个HRegionServer会有多个HRegion和一个HLog。</p>
<p>3）HRegion</p>
<p>Table在行的方向上分割为多个HRegion，HRegion是Hbase中分布式存储和负载均衡的最小单元，即不同的HRegion可以分别在不同的HRegionServer上，但同一个HRegion是不会拆分到多个HRegionServer上的。HRegion按大小分割，每个表一般只有一个HRegion，随着数据不断插入表，HRegion不断增大，当HRegion的某个列簇达到一个阀值（默认256M）时就会分成两个新的HRegion。</p>
<p>&lt;表名，StartRowKey, 创建时间&gt;</p>
<p>由目录表(-ROOT-和.META.)记录该Region的EndRowKey</p>
<p>HRegion被分配给哪个HRegionServer是完全动态的，所以需要机制来定位HRegion具体在哪个HRegionServer，Hbase使用三层结构来定位HRegion：</p>
<p>通过zk里的文件/Hbase/rs得到-ROOT-表的位置。-ROOT-表只有一个region。</p>
<p>通过-ROOT-表查找.META.表的第一个表中相应的HRegion位置。其实-ROOT-表是.META.表的第一个region；.META.表中的每一个Region在-ROOT-表中都是一行记录。</p>
<p>通过.META.表找到所要的用户表HRegion的位置。用户表的每个HRegion在.META.表中都是一行记录。-ROOT-表永远不会被分隔为多个HRegion，保证了最多需要三次跳转，就能定位到任意的region。Client会将查询的位置信息保存缓存起来，缓存不会主动失效，因此如果Client上的缓存全部失效，则需要进行6次网络来回，才能定位到正确的HRegion，其中三次用来发现缓存失效，另外三次用来获取位置信息。</p>
<p>4）Store</p>
<p>每一个HRegion由一个或多个Store组成，至少是一个Store，Hbase会把一起访问的数据放在一个Store里面，即为每个ColumnFamily建一个Store，如果有几个ColumnFamily，也就有几个Store。一个Store由一个MemStore和0或者多个StoreFile组成。 Hbase以Store的大小来判断是否需要切分HRegion。</p>
<p>5）MemStore</p>
<p>MemStore 是放在内存里的，保存修改的数据即keyValues。当MemStore的大小达到一个阀值（默认64MB）时，MemStore会被Flush到文件，即生成一个快照。目前Hbase会有一个线程来负责MemStore的Flush操作。</p>
<p>6）StoreFile</p>
<p>MemStore内存中的数据写到文件后就是StoreFile，StoreFile底层是以HFile的格式保存。</p>
<p>7）HFile</p>
<p>Hbase中KeyValue数据的存储格式，是Hadoop的二进制格式文件。 首先HFile文件是不定长的，长度固定的只有其中的两块：Trailer和FileInfo。</p>
<p>Trailer中有指针指向其他数据块的起始点，FileInfo记录了文件的一些meta信息。Data Block是Hbase IO的基本单元，为了提高效率，HRegionServer中有基于LRU的Block Cache机制。每个Data块的大小可以在创建一个Table的时候通过参数指定（默认块大小64KB），大号的Block有利于顺序Scan，小号的Block利于随机查询。每个Data块除了开头的Magic以外就是一个个KeyValue对拼接而成，Magic内容就是一些随机数字，目的是防止数据损坏，结构如下。</p>
<p align="center">
<img src="/images/bigDataGuideImgs/4.1HBase-架构-HFile.png"/>  
<p align="center">
</p>
</p>  


<p> HFile结构图如下：</p>
<p align="center">
<img src="/images/bigDataGuideImgs/4.1HBase-架构-HFile结构.png"/>  
<p align="center">
</p>
</p>  


<p>Data Block段用来保存表中的数据，这部分可以被压缩。 Meta Block段（可选的）用来保存用户自定义的kv段，可以被压缩。 FileInfo段用来保存HFile的元信息，不能被压缩，用户也可以在这一部分添加自己的元信息。 Data Block Index段（可选的）用来保存Meta Blcok的索引。 Trailer这一段是定长的。保存了每一段的偏移量，读取一个HFile时，会首先读取Trailer，Trailer保存了每个段的起始位置(段的Magic Number用来做安全check)，然后，DataBlock Index会被读取到内存中，这样，当检索某个key时，不需要扫描整个HFile，而只需从内存中找到key所在的block，通过一次磁盘io将整个 block读取到内存中，再找到需要的key。DataBlock Index采用LRU机制淘汰。 HFile的Data Block，Meta Block通常采用压缩方式存储，压缩之后可以大大减少网络IO和磁盘IO，随之而来的开销当然是需要花费cpu进行压缩和解压缩。（备注：DataBlock Index的缺陷：a) 占用过多内存　b) 启动加载时间缓慢）</p>
<p>8）HLog</p>
<p>HLog(WAL log)：WAL意为write ahead log，用来做灾难恢复使用，HLog记录数据的所有变更，一旦region server 宕机，就可以从log中进行恢复。</p>
<h2 id="面试题整理"><a href="#面试题整理" class="headerlink" title="面试题整理"></a>面试题整理</h2><h3 id="HBase的特点是什么？"><a href="#HBase的特点是什么？" class="headerlink" title="HBase的特点是什么？"></a>HBase的特点是什么？</h3><p>&emsp; 1）大：一个表可以有数十亿行，上百万列；<br>&emsp; 2）无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列；<br>&emsp; 3）面向列：面向列（族）的存储和权限控制，列（族）独立检索；<br>&emsp; 4）稀疏：空（null）列并不占用存储空间，表可以设计的非常稀疏；<br>&emsp; 5）数据多版本：每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳；<br>&emsp; 6）数据类型单一：Hbase中的数据都是字符串，没有类型。  </p>
<h3 id="HBase和Hive的区别？"><a href="#HBase和Hive的区别？" class="headerlink" title="HBase和Hive的区别？"></a>HBase和Hive的区别？</h3><p align="center">
<img src="/images/bigDataGuideImgs/4.2.6HBase和Hive区别.png"/>  
<p align="center">
</p>
</p>  


<p> &emsp; Hive和Hbase是两种基于Hadoop的不同技术—Hive是一种类SQL的引擎，并且运行MapReduce任务，Hbase是一种在Hadoop之上的NoSQL 的Key/vale数据库。<br> 当然，这两种工具是可以同时使用的。就像用Google来搜索，用FaceBook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，<br> 数据也可以从Hive写到Hbase，设置再从Hbase写回Hive。  </p>
<h3 id="HBase适用于怎样的情景？"><a href="#HBase适用于怎样的情景？" class="headerlink" title="HBase适用于怎样的情景？"></a>HBase适用于怎样的情景？</h3><p>&emsp; ① 半结构化或非结构化数据<br>&emsp; 对于数据结构字段不够确定或杂乱无章很难按一个概念去进行抽取的数据适合用HBase。以上面的例子为例，当业务发展需要存储author的email，phone，<br>address信息时RDBMS需要停机维护，而HBase支持动态增加。<br>&emsp; ② 记录非常稀疏<br>&emsp; RDBMS的行有多少列是固定的，为null的列浪费了存储空间。而如上文提到的，HBase为null的Column不会被存储，这样既节省了空间又提高了读性能。<br>&emsp; ③ 多版本数据<br>&emsp; 如上文提到的根据Row key和Column key定位到的Value可以有任意数量的版本值，因此对于需要存储变动历史记录的数据，用HBase就非常方便了。<br>比如上例中的author的Address是会变动的，业务上一般只需要最新的值，但有时可能需要查询到历史值。<br>&emsp; ④ 超大数据量<br>&emsp; 当数据量越来越大，RDBMS数据库撑不住了，就出现了读写分离策略，通过一个Master专门负责写操作，多个Slave负责读操作，服务器成本倍增。<br>随着压力增加，Master撑不住了，这时就要分库了，把关联不大的数据分开部署，一些join查询不能用了，需要借助中间层。随着数据量的进一步增加，<br>一个表的记录越来越大，查询就变得很慢，于是又得搞分表，比如按ID取模分成多个表以减少单个表的记录数。经历过这些事的人都知道过程是多么的折腾。<br>采用HBase就简单了，只需要加机器即可，HBase会自动水平切分扩展，跟Hadoop的无缝集成保障了其数据可靠性（HDFS）和海量数据分析的高性能（MapReduce）。  </p>
<h3 id="描述HBase的rowKey的设计原则？（☆☆☆☆☆）"><a href="#描述HBase的rowKey的设计原则？（☆☆☆☆☆）" class="headerlink" title="描述HBase的rowKey的设计原则？（☆☆☆☆☆）"></a>描述HBase的rowKey的设计原则？（☆☆☆☆☆）</h3><p>（1）Rowkey长度原则<br>&emsp; Rowkey 是一个二进制码流，Rowkey 的长度被很多开发者建议说设计在10~100 个字节，不过建议是越短越好，不要超过16 个字节。<br>&emsp; 原因如下：<br>&emsp; ① 数据的持久化文件HFile 中是按照KeyValue 存储的，如果Rowkey 过长比如100 个字节，1000 万列数据光Rowkey 就要占用100*1000 万=10 亿个字节，<br>将近1G 数据，这会极大影响HFile 的存储效率；<br>&emsp; ② MemStore 将缓存部分数据到内存，如果Rowkey 字段过长内存的有效利用率会降低，系统将无法缓存更多的数据，这会降低检索效率。<br>因此Rowkey 的字节长度越短越好。<br>&emsp; ③ 目前操作系统是都是64 位系统，内存8 字节对齐。控制在16 个字节，8 字节的整数倍利用操作系统的最佳特性。<br>（2）Rowkey散列原则<br>&emsp; 如果Rowkey是按时间戳的方式递增，不要将时间放在二进制码的前面，建议将Rowkey的高位作为散列字段，由程序循环生成，低位放时间字段，<br>这样将提高数据均衡分布在每个Regionserver 实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息将产生所有新数据都在一个 RegionServer 上堆积的<br>热点现象，这样在做数据检索的时候负载将会集中在个别RegionServer，降低查询效率。<br>（3）Rowkey唯一原则<br>&emsp; 必须在设计上保证其唯一性。  </p>
<h3 id="描述HBase中scan和get的功能以及实现的异同？（☆☆☆☆☆）"><a href="#描述HBase中scan和get的功能以及实现的异同？（☆☆☆☆☆）" class="headerlink" title="描述HBase中scan和get的功能以及实现的异同？（☆☆☆☆☆）"></a>描述HBase中scan和get的功能以及实现的异同？（☆☆☆☆☆）</h3><p>HBase的查询实现只提供两种方式：<br>&emsp; 1）按指定RowKey 获取唯一一条记录，get方法（org.apache.hadoop.hbase.client.Get） Get 的方法处理分两种 : 设置了ClosestRowBefore 和<br>没有设置ClosestRowBefore的rowlock。主要是用来保证行的事务性，即每个get 是以一个row 来标记的。一个row中可以有很多family 和column。<br>&emsp; 2）按指定的条件获取一批记录，scan方法(org.apache.Hadoop.hbase.client.Scan）实现条件查询功能使用的就是scan 方式。<br>&emsp; &emsp; （1）scan 可以通过setCaching 与setBatch 方法提高速度(以空间换时间)；<br>&emsp; &emsp; （2）scan 可以通过setStartRow 与setEndRow 来限定范围([start，end)start 是闭区间，end 是开区间)。范围越小，性能越高。<br>&emsp; &emsp; （3）scan 可以通过setFilter 方法添加过滤器，这也是分页、多条件查询的基础。  </p>
<h3 id="请描述HBase中scan对象的setCache和setBatch方法的使用？（☆☆☆☆☆）"><a href="#请描述HBase中scan对象的setCache和setBatch方法的使用？（☆☆☆☆☆）" class="headerlink" title="请描述HBase中scan对象的setCache和setBatch方法的使用？（☆☆☆☆☆）"></a>请描述HBase中scan对象的setCache和setBatch方法的使用？（☆☆☆☆☆）</h3><p>&emsp; setCache用于设置缓存，即设置一次RPC请求可以获取多行数据。对于缓存操作，如果行的数据量非常大，多行数据有可能超过客户端进程的内存容量，<br>由此引入批量处理这一解决方案。<br>&emsp; setBatch 用于设置批量处理，批量可以让用户选择每一次ResultScanner实例的next操作要取回多少列，例如，在扫描中设置setBatch(5)，<br>则一次next()返回的Result实例会包括5列。如果一行包括的列数超过了批量中设置的值，则可以将这一行分片，每次next操作返回一片，当一行的列数不能被批量中<br>设置的值整除时，最后一次返回的Result实例会包含比较少的列，如，一行17列，batch设置为5，则一共返回4个Result实例，这4个实例中包括的列数分别<br>为5、5、5、2。<br>&emsp; 组合使用扫描器缓存和批量大小，可以让用户方便地控制扫描一个范围内的行键所需要的RPC调用次数。Cache设置了服务器一次返回的行数，<br>而Batch设置了服务器一次返回的列数。<br>&emsp; 假如我们建立了一张有两个列族的表，添加了10行数据，每个行的每个列族下有10列，这意味着整个表一共有200列（或单元格，因为每个列只有一个版本），<br>其中每行有20列。  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/4.2.6HBase中scan对象的setCache和setBatch方法.png"/>  
<p align="center">
</p>
</p>  

<p>&emsp; ① Batch参数决定了一行数据分为几个Result，它只针对一行数据，Batch再大，也只能将一行的数据放入一个Result中。所以当一行数据有10列，<br>而Batch为100时，也只能将一行的所有列都放入一个Result，不会混合其他行；<br>&emsp; ② 缓存值决定一次RPC返回几个Result，根据Batch划分的Result个数除以缓存个数可以得到RPC消息个数（之前定义缓存值决定一次返回的行数，<br>这是不准确的，准确来说是决定一次RPC返回的Result个数，由于在引入Batch之前，一行封装为一个Result，因此定义缓存值决定一次返回的行数，但引入Batch后，<br>更准确的说法是缓存值决定了一次RPC返回的Result个数）；<br>&emsp; &emsp; RPC请求次数 = （行数 * 每行列数） / Min（每行的列数，批量大小） / 扫描器缓存<br>&emsp; 下图展示了缓存和批量两个参数如何联动，下图中有一个包含9行数据的表，每行都包含一些列。使用了一个缓存为6、批量大小为3的扫描器，<br>需要三次RPC请求来传送数据：  </p>
<p align="center">
<img src="/images/bigDataGuideImgs/4.2.6HBase Table.png"/>  
<p align="center">
</p>
</p>  


<h3 id="请详细描述HBase中一个cell的结构？"><a href="#请详细描述HBase中一个cell的结构？" class="headerlink" title="请详细描述HBase中一个cell的结构？"></a>请详细描述HBase中一个cell的结构？</h3><p>&emsp; HBase中通过row和columns确定的为一个存贮单元称为cell。<br>&emsp; Cell：由{row key, column(=<family> + <label>), version}唯一确定的单元。cell 中的数据是没有类型的，全部是字节码形式存贮。  </p>
<h3 id="简述HBase中compact用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？（☆☆☆☆☆）"><a href="#简述HBase中compact用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？（☆☆☆☆☆）" class="headerlink" title="简述HBase中compact用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？（☆☆☆☆☆）"></a>简述HBase中compact用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？（☆☆☆☆☆）</h3><p>&emsp; 在hbase中每当有memstore数据flush到磁盘之后，就形成一个storefile，当storeFile的数量达到一定程度后，就需要将 storefile 文件来<br>进行 compaction 操作。<br>&emsp; Compact 的作用：<br>&emsp; ① 合并文件<br>&emsp; ② 清除过期，多余版本的数据<br>&emsp; ③ 提高读写数据的效率<br>&emsp; HBase 中实现了两种 compaction 的方式：minor and major. 这两种 compaction 方式的区别是：<br>&emsp; 1）Minor 操作只用来做部分文件的合并操作以及包括 minVersion=0 并且设置 ttl 的过期版本清理，不做任何删除数据、多版本数据的清理工作。<br>&emsp; 2）Major 操作是对 Region 下的HStore下的所有StoreFile执行合并操作，最终的结果是整理合并出一个文件。  </p>
<h3 id="每天百亿数据存入HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？（☆☆☆☆☆）"><a href="#每天百亿数据存入HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？（☆☆☆☆☆）" class="headerlink" title="每天百亿数据存入HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？（☆☆☆☆☆）"></a>每天百亿数据存入HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？（☆☆☆☆☆）</h3><p>需求分析：<br>&emsp; 1）百亿数据：证明数据量非常大；<br>&emsp; 2）存入HBase：证明是跟HBase的写入数据有关；<br>&emsp; 3）保证数据的正确：要设计正确的数据结构保证正确性；<br>&emsp; 4）在规定时间内完成：对存入速度是有要求的。<br>解决思路：<br>&emsp; 1）数据量百亿条，什么概念呢？假设一整天60x60x24 = 86400秒都在写入数据，那么每秒的写入条数高达100万条，HBase当然是支持不了每秒百万条数据的，<br>所以这百亿条数据可能不是通过实时地写入，而是批量地导入。批量导入推荐使用BulkLoad方式（推荐阅读：Spark之读写HBase），性能是普通写入方式几倍以上；<br>&emsp; 2）存入HBase：普通写入是用JavaAPI put来实现，批量导入推荐使用BulkLoad；<br>&emsp; 3）保证数据的正确：这里需要考虑RowKey的设计、预建分区和列族设计等问题；<br>&emsp; 4）在规定时间内完成也就是存入速度不能过慢，并且当然是越快越好，使用BulkLoad。  </p>
<h3 id="请列举几个HBase优化方法？（☆☆☆☆☆）"><a href="#请列举几个HBase优化方法？（☆☆☆☆☆）" class="headerlink" title="请列举几个HBase优化方法？（☆☆☆☆☆）"></a>请列举几个HBase优化方法？（☆☆☆☆☆）</h3><p>1）减少调整<br>&emsp; 减少调整这个如何理解呢？HBase中有几个内容会动态调整，如region（分区）、HFile，所以通过一些方法来减少这些会带来I/O开销的调整。<br>&emsp; ① Region<br>&emsp; &emsp; 如果没有预建分区的话，那么随着region中条数的增加，region会进行分裂，这将增加I/O开销，所以解决方法就是根据你的RowKey设计来进行预建分区，<br>减少region的动态分裂。<br>&emsp; ② HFile<br>&emsp; &emsp; HFile是数据底层存储文件，在每个memstore进行刷新时会生成一个HFile，当HFile增加到一定程度时，会将属于一个region的HFile进行合并，<br>这个步骤会带来开销但不可避免，但是合并后HFile大小如果大于设定的值，那么HFile会重新分裂。为了减少这样的无谓的I/O开销，建议估计项目数据量大小，<br>给HFile设定一个合适的值。<br>2）减少启停<br>&emsp; 数据库事务机制就是为了更好地实现批量写入，较少数据库的开启关闭带来的开销，那么HBase中也存在频繁开启关闭带来的问题。<br>&emsp; ① 关闭Compaction，在闲时进行手动Compaction。<br>&emsp; &emsp; 因为HBase中存在Minor Compaction和Major Compaction，也就是对HFile进行合并，所谓合并就是I/O读写，大量的HFile进行肯定会带来I/O开销，<br>甚至是I/O风暴，所以为了避免这种不受控制的意外发生，建议关闭自动Compaction，在闲时进行compaction。<br>&emsp; ② 批量数据写入时采用BulkLoad。<br>&emsp; 如果通过HBase-Shell或者JavaAPI的put来实现大量数据的写入，那么性能差是肯定并且还可能带来一些意想不到的问题，所以当需要写入大量离线数据时<br>建议使用BulkLoad。<br>3）减少数据量<br>&emsp; 虽然我们是在进行大数据开发，但是如果可以通过某些方式在保证数据准确性同时减少数据量，何乐而不为呢？<br>&emsp; ① 开启过滤，提高查询速度<br>&emsp; &emsp; 开启BloomFilter，BloomFilter是列族级别的过滤，在生成一个StoreFile同时会生成一个MetaBlock，用于查询时过滤数据<br>&emsp; ② 使用压缩<br>&emsp; &emsp; 一般推荐使用Snappy和LZO压缩<br>4）合理设计<br>&emsp; 在一张HBase表格中RowKey和ColumnFamily的设计是非常重要，好的设计能够提高性能和保证数据的准确性<br>&emsp; ① RowKey设计：应该具备以下几个属性<br>&emsp; &emsp; 散列性：散列性能够保证相同相似的rowkey聚合，相异的rowkey分散，有利于查询。<br>&emsp; &emsp; 简短性：rowkey作为key的一部分存储在HFile中，如果为了可读性将rowKey设计得过长，那么将会增加存储压力。<br>&emsp; &emsp; 唯一性：rowKey必须具备明显的区别性。<br>&emsp; &emsp; 业务性：举例来说：<br>&emsp; &emsp; 假如我的查询条件比较多，而且不是针对列的条件，那么rowKey的设计就应该支持多条件查询。<br>&emsp; &emsp; 如果我的查询要求是最近插入的数据优先，那么rowKey则可以采用叫上Long.Max-时间戳的方式，这样rowKey就是递减排列。<br>&emsp; ② 列族的设计：列族的设计需要看应用场景<br>&emsp; &emsp; 优势：HBase中数据时按列进行存储的，那么查询某一列族的某一列时就不需要全盘扫描，只需要扫描某一列族，减少了读I/O；<br>其实多列族设计对减少的作用不是很明显，适用于读多写少的场景<br>&emsp; &emsp; 劣势：降低了写的I/O性能。原因如下：数据写到store以后是先缓存在memstore中，同一个region中存在多个列族则存在多个store，<br>每个store都一个memstore，当其实memstore进行flush时，属于同一个region的store中的memstore都会进行flush，增加I/O开销。  </p>
<h3 id="Region如何预建分区？"><a href="#Region如何预建分区？" class="headerlink" title="Region如何预建分区？"></a>Region如何预建分区？</h3><p>&emsp; 预分区的目的主要是在创建表的时候指定分区数，提前规划表有多个分区，以及每个分区的区间范围，这样在存储的时候rowkey按照分区的区间存储，<br>可以避免region热点问题。<br>&emsp; 通常有两种方案：<br>&emsp; 方案1：shell 方法<br>&emsp; &emsp; create ‘tb_splits’, {NAME =&gt; ‘cf’,VERSIONS=&gt; 3},{SPLITS =&gt; [‘10’,’20’,’30’]}<br>&emsp; 方案2：JAVA程序控制<br>&emsp; &emsp; ① 取样，先随机生成一定数量的rowkey,将取样数据按升序排序放到一个集合里；<br>&emsp; &emsp; ② 根据预分区的region个数，对整个集合平均分割，即是相关的splitKeys；<br>&emsp; &emsp; ③ HBaseAdmin.createTable(HTableDescriptor tableDescriptor,byte[][]splitkeys)可以指定预分区的splitKey，<br>即是指定region间的rowkey临界值。  </p>
<h3 id="HRegionServer宕机如何处理？（☆☆☆☆☆）"><a href="#HRegionServer宕机如何处理？（☆☆☆☆☆）" class="headerlink" title="HRegionServer宕机如何处理？（☆☆☆☆☆）"></a>HRegionServer宕机如何处理？（☆☆☆☆☆）</h3><p>1）ZooKeeper会监控HRegionServer的上下线情况，当ZK发现某个HRegionServer宕机之后会通知HMaster进行失效备援；<br>2）该HRegionServer会停止对外提供服务，就是它所负责的region暂时停止对外提供服务；<br>3）HMaster会将该HRegionServer所负责的region转移到其他HRegionServer上，并且会对HRegionServer上存在memstore中还未持久化到磁盘中的数据进行恢复；<br>4）这个恢复的工作是由WAL重播来完成，这个过程如下：<br>&emsp; ① wal实际上就是一个文件，存在/hbase/WAL/对应RegionServer路径下。<br>&emsp; ② 宕机发生时，读取该RegionServer所对应的路径下的wal文件，然后根据不同的region切分成不同的临时文件recover.edits。<br>&emsp; ③ 当region被分配到新的RegionServer中，RegionServer读取region时会进行是否存在recover.edits，如果有则进行恢复。  </p>
<h3 id="HBase读写流程？（☆☆☆☆☆）"><a href="#HBase读写流程？（☆☆☆☆☆）" class="headerlink" title="HBase读写流程？（☆☆☆☆☆）"></a>HBase读写流程？（☆☆☆☆☆）</h3><p>&emsp; <strong>读</strong>：<br>&emsp; ① HRegionServer保存着meta表以及表数据，要访问表数据，首先Client先去访问zookeeper，从zookeeper里面获取meta表所在的位置信息，<br>即找到这个meta表在哪个HRegionServer上保存着。<br>&emsp; ② 接着Client通过刚才获取到的HRegionServer的IP来访问Meta表所在的HRegionServer，从而读取到Meta，进而获取到Meta表中存放的元数据。<br>&emsp; ③ Client通过元数据中存储的信息，访问对应的HRegionServer，然后扫描所在HRegionServer的Memstore和Storefile来查询数据。<br>&emsp; ④ 最后HRegionServer把查询到的数据响应给Client。<br>&emsp; <strong>写</strong>：<br>&emsp; ① Client先访问zookeeper，找到Meta表，并获取Meta表元数据。<br>&emsp; ② 确定当前将要写入的数据所对应的HRegion和HRegionServer服务器。<br>&emsp; ③ Client向该HRegionServer服务器发起写入数据请求，然后HRegionServer收到请求并响应。<br>&emsp; ④ Client先把数据写入到HLog，以防止数据丢失。<br>&emsp; ⑤ 然后将数据写入到Memstore。<br>&emsp; ⑥ 如果HLog和Memstore均写入成功，则这条数据写入成功。<br>&emsp; ⑦ 如果Memstore达到阈值，会把Memstore中的数据flush到Storefile中。<br>&emsp; ⑧ 当Storefile越来越多，会触发Compact合并操作，把过多的Storefile合并成一个大的Storefile。<br>&emsp; ⑨ 当Storefile越来越大，Region也会越来越大，达到阈值后，会触发Split操作，将Region一分为二。  </p>
<h3 id="HBase内部机制是什么？"><a href="#HBase内部机制是什么？" class="headerlink" title="HBase内部机制是什么？"></a>HBase内部机制是什么？</h3><p>&emsp; Hbase是一个能适应联机业务的数据库系统<br>&emsp; 物理存储：hbase的持久化数据是将数据存储在HDFS上。<br>&emsp; 存储管理：一个表是划分为很多region的，这些region分布式地存放在很多regionserver上Region内部还可以划分为store，<br>store内部有memstore和storefile。<br>&emsp; 版本管理：hbase中的数据更新本质上是不断追加新的版本，通过compact操作来做版本间的文件合并Region的split。<br>&emsp; 集群管理：ZooKeeper + HMaster + HRegionServer。  </p>
<h3 id="Hbase中的memstore是用来做什么的？"><a href="#Hbase中的memstore是用来做什么的？" class="headerlink" title="Hbase中的memstore是用来做什么的？"></a>Hbase中的memstore是用来做什么的？</h3><p>&emsp; hbase为了保证随机读取的性能，所以hfile里面的rowkey是有序的。当客户端的请求在到达regionserver之后，为了保证写入rowkey的有序性，<br>所以不能将数据立刻写入到hfile中，而是将每个变更操作保存在内存中，也就是memstore中。memstore能够很方便的支持操作的随机插入，<br>并保证所有的操作在内存中是有序的。当memstore达到一定的量之后，会将memstore里面的数据flush到hfile中，这样能充分利用hadoop写入大文件的性能优势，<br>提高写入性能。<br>&emsp; 由于memstore是存放在内存中，如果regionserver因为某种原因死了，会导致内存中数据丢失。所有为了保证数据不丢失，<br>hbase将更新操作在写入memstore之前会写入到一个write ahead log(WAL)中。WAL文件是追加、顺序写入的，WAL每个regionserver只有一个，<br>同一个regionserver上所有region写入同一个的WAL文件。这样当某个regionserver失败时，可以通过WAL文件，将所有的操作顺序重新加载到memstore中。  </p>
<h3 id="HBase在进行模型设计时重点在什么地方？一张表中定义多少个Column-Family最合适？为什么？（☆☆☆☆☆）"><a href="#HBase在进行模型设计时重点在什么地方？一张表中定义多少个Column-Family最合适？为什么？（☆☆☆☆☆）" class="headerlink" title="HBase在进行模型设计时重点在什么地方？一张表中定义多少个Column Family最合适？为什么？（☆☆☆☆☆）"></a>HBase在进行模型设计时重点在什么地方？一张表中定义多少个Column Family最合适？为什么？（☆☆☆☆☆）</h3><p>&emsp; Column Family的个数具体看表的数据，一般来说划分标准是根据数据访问频度，如一张表里有些列访问相对频繁，而另一些列访问很少，<br>这时可以把这张表划分成两个列族，分开存储，提高访问效率。  </p>
<h3 id="如何提高HBase客户端的读写性能？请举例说明（☆☆☆☆☆）"><a href="#如何提高HBase客户端的读写性能？请举例说明（☆☆☆☆☆）" class="headerlink" title="如何提高HBase客户端的读写性能？请举例说明（☆☆☆☆☆）"></a>如何提高HBase客户端的读写性能？请举例说明（☆☆☆☆☆）</h3><p>&emsp; ① 开启bloomfilter过滤器，开启bloomfilter比没开启要快3、4倍<br>&emsp; ② Hbase对于内存有特别的需求，在硬件允许的情况下配足够多的内存给它<br>&emsp; ③ 通过修改hbase-env.sh中的 export HBASE_HEAPSIZE=3000  #这里默认为1000m<br>&emsp; ④ 增大RPC数量<br>&emsp; &emsp; 通过修改hbase-site.xml中的hbase.regionserver.handler.count属性，可以适当的放大RPC数量，默认值为10有点小。  </p>
<h3 id="HBase集群安装注意事项？"><a href="#HBase集群安装注意事项？" class="headerlink" title="HBase集群安装注意事项？"></a>HBase集群安装注意事项？</h3><p>&emsp; ① HBase需要HDFS的支持，因此安装HBase前确保Hadoop集群安装完成；<br>&emsp; ② HBase需要ZooKeeper集群的支持，因此安装HBase前确保ZooKeeper集群安装完成；<br>&emsp; ③ 注意HBase与Hadoop的版本兼容性；<br>&emsp; ④ 注意hbase-env.sh配置文件和hbase-site.xml配置文件的正确配置；<br>&emsp; ⑤ 注意regionservers配置文件的修改；<br>&emsp; ⑥ 注意集群中的各个节点的时间必须同步，否则启动HBase集群将会报错。  </p>
<h3 id="直接将时间戳作为行健，在写入单个region-时候会发生热点问题，为什么呢？（☆☆☆☆☆）"><a href="#直接将时间戳作为行健，在写入单个region-时候会发生热点问题，为什么呢？（☆☆☆☆☆）" class="headerlink" title="直接将时间戳作为行健，在写入单个region 时候会发生热点问题，为什么呢？（☆☆☆☆☆）"></a>直接将时间戳作为行健，在写入单个region 时候会发生热点问题，为什么呢？（☆☆☆☆☆）</h3><p>&emsp; region中的rowkey是有序存储，若时间比较集中。就会存储到一个region中，这样一个region的数据变多，其它的region数据很少，加载数据就会很慢，<br>直到region分裂，此问题才会得到缓解。  </p>
<h3 id="请描述如何解决HBase中region太小和region太大带来的冲突？（☆☆☆☆☆）"><a href="#请描述如何解决HBase中region太小和region太大带来的冲突？（☆☆☆☆☆）" class="headerlink" title="请描述如何解决HBase中region太小和region太大带来的冲突？（☆☆☆☆☆）"></a>请描述如何解决HBase中region太小和region太大带来的冲突？（☆☆☆☆☆）</h3><p>&emsp; Region过大会发生多次compaction，将数据读一遍并重写一遍到hdfs 上，占用io，region过小会造成多次split，region 会下线，影响访问服务，<br>最佳的解决方法是调整hbase.hregion. max.filesize 为256m。  </p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/bigdata/" rel="tag"># bigdata</a>
              <a href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag"># 面试</a>
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
              <a href="/tags/Hive/" rel="tag"># Hive</a>
              <a href="/tags/Kafka/" rel="tag"># Kafka</a>
              <a href="/tags/HBase/" rel="tag"># HBase</a>
              <a href="/tags/Spark/" rel="tag"># Spark</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/01/26/%E8%AE%B0%E5%BD%95%E5%90%84%E7%A7%8D%E8%B8%A9%E5%9D%91/" rel="prev" title="记录各种踩坑">
      <i class="fa fa-chevron-left"></i> 记录各种踩坑
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop"><span class="nav-number">1.</span> <span class="nav-text">Hadoop</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E5%9F%BA%E7%A1%80"><span class="nav-number">1.1.</span> <span class="nav-text">Hadoop基础</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%88%E8%AF%B4%E4%B8%8BHadoop%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">1.1.1.</span> <span class="nav-text">先说下Hadoop是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B4%E4%B8%8BHadoop%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="nav-number">1.1.2.</span> <span class="nav-text">说下Hadoop核心组件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E4%BD%9C%E7%94%A8"><span class="nav-number">1.1.3.</span> <span class="nav-text">Hadoop核心组件作用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E7%9A%84%E6%9C%80%E4%B8%BB%E8%A6%81%E7%93%B6%E9%A2%88"><span class="nav-number">1.1.4.</span> <span class="nav-text">集群的最主要瓶颈</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="nav-number">1.1.5.</span> <span class="nav-text">Hadoop运行模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E7%94%9F%E6%80%81%E5%9C%88%E7%9A%84%E7%BB%84%E4%BB%B6%E5%B9%B6%E5%81%9A%E7%AE%80%E8%A6%81%E6%8F%8F%E8%BF%B0"><span class="nav-number">1.1.6.</span> <span class="nav-text">Hadoop生态圈的组件并做简要描述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A%E2%80%9Chadoop%E2%80%9D%E5%92%8C%E2%80%9Chadoop-%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F%E2%80%9D%E4%B8%A4%E4%B8%AA%E6%A6%82%E5%BF%B5"><span class="nav-number">1.1.7.</span> <span class="nav-text">解释“hadoop”和“hadoop 生态系统”两个概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E5%88%97%E5%87%BA%E6%AD%A3%E5%B8%B8%E5%B7%A5%E4%BD%9C%E7%9A%84Hadoop%E9%9B%86%E7%BE%A4%E4%B8%ADHadoop%E9%83%BD%E5%88%86%E5%88%AB%E9%9C%80%E8%A6%81%E5%90%AF%E5%8A%A8%E5%93%AA%E4%BA%9B%E8%BF%9B%E7%A8%8B%EF%BC%8C%E5%AE%83%E4%BB%AC%E7%9A%84%E4%BD%9C%E7%94%A8%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">1.1.8.</span> <span class="nav-text">请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS"><span class="nav-number">1.2.</span> <span class="nav-text">HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-%E4%B8%AD%E7%9A%84-block-%E9%BB%98%E8%AE%A4%E4%BF%9D%E5%AD%98%E5%87%A0%E4%BB%BD%EF%BC%9F"><span class="nav-number">1.2.1.</span> <span class="nav-text">HDFS 中的 block 默认保存几份？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-%E9%BB%98%E8%AE%A4-BlockSize-%E6%98%AF%E5%A4%9A%E5%A4%A7%EF%BC%9F"><span class="nav-number">1.2.2.</span> <span class="nav-text">HDFS 默认 BlockSize 是多大？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B4%9F%E8%B4%A3HDFS%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E7%9A%84%E6%98%AF%E5%93%AA%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%9F"><span class="nav-number">1.2.3.</span> <span class="nav-text">负责HDFS数据存储的是哪一部分？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SecondaryNameNode%E7%9A%84%E7%9B%AE%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">1.2.4.</span> <span class="nav-text">SecondaryNameNode的目的是什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F%E8%AE%BE%E7%BD%AE%EF%BC%8C%E5%A2%9E%E5%A4%A7%E6%9C%89%E4%BB%80%E4%B9%88%E5%BD%B1%E5%93%8D%EF%BC%9F"><span class="nav-number">1.2.5.</span> <span class="nav-text">文件大小设置，增大有什么影响？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop%E7%9A%84%E5%9D%97%E5%A4%A7%E5%B0%8F%EF%BC%8C%E4%BB%8E%E5%93%AA%E4%B8%AA%E7%89%88%E6%9C%AC%E5%BC%80%E5%A7%8B%E6%98%AF128M"><span class="nav-number">1.2.6.</span> <span class="nav-text">hadoop的块大小，从哪个版本开始是128M</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E7%9A%84%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.2.7.</span> <span class="nav-text">HDFS的存储机制（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#secondary-namenode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.2.8.</span> <span class="nav-text">secondary namenode工作机制（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NameNode%E4%B8%8ESecondaryNameNode-%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.2.9.</span> <span class="nav-text">NameNode与SecondaryNameNode 的区别与联系？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.2.10.</span> <span class="nav-text">HDFS组成架构（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HAnamenode-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84-%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.2.11.</span> <span class="nav-text">HAnamenode 是如何工作的? （☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3"><span class="nav-number">1.2.12.</span> <span class="nav-text">HDFS读写数据流程详解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%89%88%E6%9C%AC%EF%BC%9A%E7%AE%80%E6%B4%81%E7%89%88"><span class="nav-number">1.2.12.1.</span> <span class="nav-text">第一个版本：简洁版</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E4%B8%AA%E7%89%88%E6%9C%AC%EF%BC%9A%E8%AF%A6%E7%BB%86%E7%89%88%EF%BC%8C%E6%9C%89%E5%8A%A9%E4%BA%8E%E7%90%86%E8%A7%A3"><span class="nav-number">1.2.12.2.</span> <span class="nav-text">第二个版本：详细版，有助于理解</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce"><span class="nav-number">1.3.</span> <span class="nav-text">MapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B0%88%E8%B0%88Hadoop%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%8F%8A%E8%87%AA%E5%AE%9A%E4%B9%89bean%E5%AF%B9%E8%B1%A1%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E5%8C%96"><span class="nav-number">1.3.1.</span> <span class="nav-text">谈谈Hadoop序列化和反序列化及自定义bean对象实现序列化?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FileInputFormat%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.3.2.</span> <span class="nav-text">FileInputFormat切片机制（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8%E4%B8%80%E4%B8%AA%E8%BF%90%E8%A1%8C%E7%9A%84Hadoop-%E4%BB%BB%E5%8A%A1%E4%B8%AD%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AFInputSplit%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.3.3.</span> <span class="nav-text">在一个运行的Hadoop 任务中，什么是InputSplit？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%88%A4%E5%AE%9A%E4%B8%80%E4%B8%AAjob%E7%9A%84map%E5%92%8Creduce%E7%9A%84%E6%95%B0%E9%87%8F"><span class="nav-number">1.3.4.</span> <span class="nav-text">如何判定一个job的map和reduce的数量?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Maptask%E7%9A%84%E4%B8%AA%E6%95%B0%E7%94%B1%E4%BB%80%E4%B9%88%E5%86%B3%E5%AE%9A%EF%BC%9F"><span class="nav-number">1.3.5.</span> <span class="nav-text">Maptask的个数由什么决定？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapTask%E5%92%8CReduceTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89%EF%BC%88%E4%B9%9F%E5%8F%AF%E5%9B%9E%E7%AD%94MapReduce%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%EF%BC%89"><span class="nav-number">1.3.6.</span> <span class="nav-text">MapTask和ReduceTask工作机制（☆☆☆☆☆）（也可回答MapReduce工作原理）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%8F%E8%BF%B0mapReduce%E6%9C%89%E5%87%A0%E7%A7%8D%E6%8E%92%E5%BA%8F%E5%8F%8A%E6%8E%92%E5%BA%8F%E5%8F%91%E7%94%9F%E7%9A%84%E9%98%B6%E6%AE%B5%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.3.7.</span> <span class="nav-text">描述mapReduce有几种排序及排序发生的阶段（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%8F%E8%BF%B0mapReduce%E4%B8%ADshuffle%E9%98%B6%E6%AE%B5%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%8C%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96shuffle%E9%98%B6%E6%AE%B5%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.3.8.</span> <span class="nav-text">描述mapReduce中shuffle阶段的工作流程，如何优化shuffle阶段（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%8F%E8%BF%B0mapReduce%E4%B8%ADcombiner%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%8C%E4%B8%80%E8%88%AC%E4%BD%BF%E7%94%A8%E6%83%85%E6%99%AF%EF%BC%8C%E5%93%AA%E4%BA%9B%E6%83%85%E5%86%B5%E4%B8%8D%E9%9C%80%E8%A6%81%EF%BC%8C%E5%8F%8A%E5%92%8Creduce%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="nav-number">1.3.9.</span> <span class="nav-text">描述mapReduce中combiner的作用是什么，一般使用情景，哪些情况不需要，及和reduce的区别？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%E5%AE%9A%E4%B9%89partitioner%EF%BC%8C%E9%82%A3%E6%95%B0%E6%8D%AE%E5%9C%A8%E8%A2%AB%E9%80%81%E8%BE%BEreducer%E5%89%8D%E6%98%AF%E5%A6%82%E4%BD%95%E8%A2%AB%E5%88%86%E5%8C%BA%E7%9A%84%EF%BC%9F"><span class="nav-number">1.3.10.</span> <span class="nav-text">如果没有定义partitioner，那数据在被送达reducer前是如何被分区的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce-%E5%87%BA%E7%8E%B0%E5%8D%95%E7%82%B9%E8%B4%9F%E8%BD%BD%E5%A4%9A%E5%A4%A7%EF%BC%8C%E6%80%8E%E4%B9%88%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1%EF%BC%9F-%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.3.11.</span> <span class="nav-text">MapReduce 出现单点负载多大，怎么负载平衡？ （☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce-%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0-TopN%EF%BC%9F-%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.3.12.</span> <span class="nav-text">MapReduce 怎么实现 TopN？ （☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%EF%BC%88Distributedcache%EF%BC%89%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.3.13.</span> <span class="nav-text">Hadoop的缓存机制（Distributedcache）（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8mapReduce%E5%AE%9E%E7%8E%B0%E4%B8%A4%E4%B8%AA%E8%A1%A8%E7%9A%84join-%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.3.14.</span> <span class="nav-text">如何使用mapReduce实现两个表的join?（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E8%AE%A1%E7%AE%97%E4%B8%8D%E8%83%BD%E7%94%A8mr%E6%9D%A5%E6%8F%90%E9%80%9F%EF%BC%9F"><span class="nav-number">1.3.15.</span> <span class="nav-text">什么样的计算不能用mr来提速？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ETL%E6%98%AF%E5%93%AA%E4%B8%89%E4%B8%AA%E5%8D%95%E8%AF%8D%E7%9A%84%E7%BC%A9%E5%86%99"><span class="nav-number">1.3.16.</span> <span class="nav-text">ETL是哪三个单词的缩写</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D%E4%B8%8BMapReduce"><span class="nav-number">1.3.17.</span> <span class="nav-text">介绍下MapReduce</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">1.3.18.</span> <span class="nav-text">MapReduce优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E7%82%B9"><span class="nav-number">1.3.18.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%BA%E7%82%B9"><span class="nav-number">1.3.18.2.</span> <span class="nav-text">缺点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Yarn"><span class="nav-number">1.4.</span> <span class="nav-text">Yarn</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E8%BF%B0hadoop1%E4%B8%8Ehadoop2-%E7%9A%84%E6%9E%B6%E6%9E%84%E5%BC%82%E5%90%8C"><span class="nav-number">1.4.1.</span> <span class="nav-text">简述hadoop1与hadoop2 的架构异同</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E4%BA%A7%E7%94%9F-yarn-%E5%AE%83%E8%A7%A3%E5%86%B3%E4%BA%86%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E5%8A%BF%EF%BC%9F"><span class="nav-number">1.4.2.</span> <span class="nav-text">为什么会产生 yarn,它解决了什么问题，有什么优势？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95-%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.4.3.</span> <span class="nav-text">HDFS的数据压缩算法?（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8%E6%80%BB%E7%BB%93%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.4.4.</span> <span class="nav-text">Hadoop的调度器总结（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce-2-0-%E5%AE%B9%E9%94%99%E6%80%A7%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.4.5.</span> <span class="nav-text">MapReduce 2.0 容错性（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mapreduce%E6%8E%A8%E6%B5%8B%E6%89%A7%E8%A1%8C%E7%AE%97%E6%B3%95%E5%8F%8A%E5%8E%9F%E7%90%86%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.4.6.</span> <span class="nav-text">mapreduce推测执行算法及原理（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D%E4%B8%8BYARN"><span class="nav-number">1.4.7.</span> <span class="nav-text">介绍下YARN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98"><span class="nav-number">1.5.</span> <span class="nav-text">优化问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E8%B7%91%E5%BE%97%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.5.1.</span> <span class="nav-text">MapReduce跑得慢的原因？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.5.2.</span> <span class="nav-text">MapReduce优化方法（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E5%B0%8F%E6%96%87%E4%BB%B6%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">1.5.3.</span> <span class="nav-text">HDFS小文件优化方法（☆☆☆☆☆）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hive"><span class="nav-number">2.</span> <span class="nav-text">Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive%E6%A6%82%E8%BF%B0"><span class="nav-number">2.1.</span> <span class="nav-text">Hive概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFHive"><span class="nav-number">2.1.1.</span> <span class="nav-text">什么是Hive</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">2.1.2.</span> <span class="nav-text">Hive优缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86"><span class="nav-number">2.1.3.</span> <span class="nav-text">Hive架构原理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89"><span class="nav-number">2.2.</span> <span class="nav-text">Hive面试题整理（一）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E8%A1%A8%E5%85%B3%E8%81%94%E6%9F%A5%E8%AF%A2%EF%BC%8C%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">2.2.1.</span> <span class="nav-text">Hive表关联查询，如何解决数据倾斜的问题？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E7%9A%84HSQL%E8%BD%AC%E6%8D%A2%E4%B8%BAMapReduce%E7%9A%84%E8%BF%87%E7%A8%8B%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">2.2.2.</span> <span class="nav-text">Hive的HSQL转换为MapReduce的过程？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E5%BA%95%E5%B1%82%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%A4%E4%BA%92%E5%8E%9F%E7%90%86%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">2.2.3.</span> <span class="nav-text">Hive底层与数据库交互原理？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E7%9A%84%E4%B8%A4%E5%BC%A0%E8%A1%A8%E5%85%B3%E8%81%94%EF%BC%8C%E4%BD%BF%E7%94%A8MapReduce%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">2.2.4.</span> <span class="nav-text">Hive的两张表关联，使用MapReduce怎么实现？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E8%B0%88%E4%B8%80%E4%B8%8BHive%E7%9A%84%E7%89%B9%E7%82%B9%EF%BC%8CHive%E5%92%8CRDBMS%E6%9C%89%E4%BB%80%E4%B9%88%E5%BC%82%E5%90%8C%EF%BC%9F"><span class="nav-number">2.2.5.</span> <span class="nav-text">请谈一下Hive的特点，Hive和RDBMS有什么异同？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E8%AF%B4%E6%98%8Ehive%E4%B8%AD-Sort-By%EF%BC%8COrder-By%EF%BC%8CCluster-By%EF%BC%8CDistrbute-By%E5%90%84%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D%EF%BC%9F"><span class="nav-number">2.2.6.</span> <span class="nav-text">请说明hive中 Sort By，Order By，Cluster By，Distrbute By各代表什么意思？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%99%E5%87%BAhive%E4%B8%ADsplit%E3%80%81coalesce%E5%8F%8Acollect-list%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95%EF%BC%88%E5%8F%AF%E4%B8%BE%E4%BE%8B%EF%BC%89%EF%BC%9F"><span class="nav-number">2.2.7.</span> <span class="nav-text">写出hive中split、coalesce及collect_list函数的用法（可举例）？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E5%BC%8F%E4%BF%9D%E5%AD%98%E5%85%83%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%90%84%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E7%82%B9%EF%BC%9F"><span class="nav-number">2.2.8.</span> <span class="nav-text">Hive有哪些方式保存元数据，各有哪些特点？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E5%86%85%E9%83%A8%E8%A1%A8%E5%92%8C%E5%A4%96%E9%83%A8%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="nav-number">2.2.9.</span> <span class="nav-text">Hive内部表和外部表的区别？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-%E4%B8%AD%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8FTextFile%E3%80%81SequenceFile%E3%80%81RCfile-%E3%80%81ORCfile%E5%90%84%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="nav-number">2.2.10.</span> <span class="nav-text">Hive 中的压缩格式TextFile、SequenceFile、RCfile 、ORCfile各有什么区别？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%80%E6%9C%89%E7%9A%84Hive%E4%BB%BB%E5%8A%A1%E9%83%BD%E4%BC%9A%E6%9C%89MapReduce%E7%9A%84%E6%89%A7%E8%A1%8C%E5%90%97%EF%BC%9F"><span class="nav-number">2.2.11.</span> <span class="nav-text">所有的Hive任务都会有MapReduce的执行吗？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive%E7%9A%84%E5%87%BD%E6%95%B0%EF%BC%9AUDF%E3%80%81UDAF%E3%80%81UDTF%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="nav-number">2.2.12.</span> <span class="nav-text">Hive的函数：UDF、UDAF、UDTF的区别？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B4%E8%AF%B4%E5%AF%B9Hive%E6%A1%B6%E8%A1%A8%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%9F"><span class="nav-number">2.2.13.</span> <span class="nav-text">说说对Hive桶表的理解？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86%EF%BC%88%E4%BA%8C%EF%BC%89"><span class="nav-number">2.3.</span> <span class="nav-text">Hive面试题整理（二）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Fetch%E6%8A%93%E5%8F%96"><span class="nav-number">2.3.1.</span> <span class="nav-text">Fetch抓取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.3.2.</span> <span class="nav-text">本地模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A8%E7%9A%84%E4%BC%98%E5%8C%96"><span class="nav-number">2.3.3.</span> <span class="nav-text">表的优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E8%A1%A8%E3%80%81%E5%A4%A7%E8%A1%A8Join"><span class="nav-number">2.3.4.</span> <span class="nav-text">小表、大表Join</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%A7%E8%A1%A8Join%E5%A4%A7%E8%A1%A8"><span class="nav-number">2.3.5.</span> <span class="nav-text">大表Join大表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Group-By"><span class="nav-number">2.3.6.</span> <span class="nav-text">Group By</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Count-Distinct-%E5%8E%BB%E9%87%8D%E7%BB%9F%E8%AE%A1"><span class="nav-number">2.3.7.</span> <span class="nav-text">Count(Distinct) 去重统计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AC%9B%E5%8D%A1%E5%B0%94%E7%A7%AF"><span class="nav-number">2.3.8.</span> <span class="nav-text">笛卡尔积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%8C%E5%88%97%E8%BF%87%E6%BB%A4"><span class="nav-number">2.3.9.</span> <span class="nav-text">行列过滤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="nav-number">2.3.10.</span> <span class="nav-text">数据倾斜</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Map%E6%95%B0"><span class="nav-number">2.3.11.</span> <span class="nav-text">Map数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E5%90%88%E5%B9%B6"><span class="nav-number">2.3.12.</span> <span class="nav-text">小文件进行合并</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%8D%E6%9D%82%E6%96%87%E4%BB%B6%E5%A2%9E%E5%8A%A0Map%E6%95%B0"><span class="nav-number">2.3.13.</span> <span class="nav-text">复杂文件增加Map数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reduce%E6%95%B0"><span class="nav-number">2.3.14.</span> <span class="nav-text">Reduce数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C"><span class="nav-number">2.3.15.</span> <span class="nav-text">并行执行</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Kafka"><span class="nav-number">3.</span> <span class="nav-text">Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D%E4%B8%8BKafka%EF%BC%8CKafka%E7%9A%84%E4%BD%9C%E7%94%A8%EF%BC%9FKafka%E7%9A%84%E7%BB%84%E4%BB%B6%EF%BC%9F%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9F"><span class="nav-number">3.1.</span> <span class="nav-text">介绍下Kafka，Kafka的作用？Kafka的组件？适用场景？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89"><span class="nav-number">3.2.</span> <span class="nav-text">Kafka面试题总结（一）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E7%82%B9%EF%BC%9F"><span class="nav-number">3.2.1.</span> <span class="nav-text">Kafka 都有哪些特点？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E7%AE%80%E8%BF%B0%E4%B8%8B%E4%BD%A0%E5%9C%A8%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF%E4%B8%8B%E4%BC%9A%E9%80%89%E6%8B%A9-Kafka%EF%BC%9F"><span class="nav-number">3.2.2.</span> <span class="nav-text">请简述下你在哪些场景下会选择 Kafka？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%9E%B6%E6%9E%84%EF%BC%9F"><span class="nav-number">3.2.3.</span> <span class="nav-text">Kafka 的设计架构？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E5%88%86%E5%8C%BA%E7%9A%84%E7%9B%AE%E7%9A%84%EF%BC%9F"><span class="nav-number">3.2.4.</span> <span class="nav-text">Kafka 分区的目的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E6%98%AF%E5%A6%82%E4%BD%95%E5%81%9A%E5%88%B0%E6%B6%88%E6%81%AF%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7%EF%BC%9F"><span class="nav-number">3.2.5.</span> <span class="nav-text">Kafka 是如何做到消息的有序性？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E7%9A%84%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="nav-number">3.2.6.</span> <span class="nav-text">Kafka 的高可靠性是怎么实现的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISR%E3%80%81OSR%E3%80%81AR-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">3.2.7.</span> <span class="nav-text">ISR、OSR、AR 是什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LEO%E3%80%81HW%E3%80%81LSO%E3%80%81LW%E7%AD%89%E5%88%86%E5%88%AB%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">3.2.8.</span> <span class="nav-text">LEO、HW、LSO、LW等分别代表什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%9C%89%E5%87%A0%E7%A7%8D%EF%BC%9F"><span class="nav-number">3.2.9.</span> <span class="nav-text">数据传输的事务有几种？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E6%B6%88%E8%B4%B9%E6%8C%87%E5%AE%9A%E5%88%86%E5%8C%BA%E6%B6%88%E6%81%AF%EF%BC%9F"><span class="nav-number">3.2.10.</span> <span class="nav-text">Kafka 消费者是否可以消费指定分区消息？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E6%B6%88%E6%81%AF%E6%98%AF%E9%87%87%E7%94%A8Pull%E6%A8%A1%E5%BC%8F%EF%BC%8C%E8%BF%98%E6%98%AFPush%E6%A8%A1%E5%BC%8F%EF%BC%9F"><span class="nav-number">3.2.11.</span> <span class="nav-text">Kafka消息是采用Pull模式，还是Push模式？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E9%AB%98%E6%95%88%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E8%AE%BE%E8%AE%A1%E7%89%B9%E7%82%B9%EF%BC%9F"><span class="nav-number">3.2.12.</span> <span class="nav-text">Kafka 高效文件存储设计特点？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E5%88%9B%E5%BB%BATopic%E6%97%B6%E5%A6%82%E4%BD%95%E5%B0%86%E5%88%86%E5%8C%BA%E6%94%BE%E7%BD%AE%E5%88%B0%E4%B8%8D%E5%90%8C%E7%9A%84Broker%E4%B8%AD%EF%BC%9F"><span class="nav-number">3.2.13.</span> <span class="nav-text">Kafka创建Topic时如何将分区放置到不同的Broker中？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E6%96%B0%E5%BB%BA%E7%9A%84%E5%88%86%E5%8C%BA%E4%BC%9A%E5%9C%A8%E5%93%AA%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%88%9B%E5%BB%BA%EF%BC%9F"><span class="nav-number">3.2.14.</span> <span class="nav-text">Kafka新建的分区会在哪个目录下创建？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B0%88%E4%B8%80%E8%B0%88-Kafka-%E7%9A%84%E5%86%8D%E5%9D%87%E8%A1%A1"><span class="nav-number">3.2.15.</span> <span class="nav-text">谈一谈 Kafka 的再均衡</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-number">3.2.16.</span> <span class="nav-text">Kafka分区分配策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%90%9E%E5%90%90%E7%8E%87%E7%9A%84%EF%BC%9F"><span class="nav-number">3.2.17.</span> <span class="nav-text">Kafka 是如何实现高吞吐率的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="nav-number">3.2.18.</span> <span class="nav-text">Kafka 缺点？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E6%96%B0%E6%97%A7%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="nav-number">3.2.19.</span> <span class="nav-text">Kafka 新旧消费者的区别？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E5%88%86%E5%8C%BA%E6%95%B0%E5%8F%AF%E4%BB%A5%E5%A2%9E%E5%8A%A0%E6%88%96%E5%87%8F%E5%B0%91%E5%90%97%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">3.2.20.</span> <span class="nav-text">Kafka 分区数可以增加或减少吗？为什么？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86%EF%BC%88%E4%BA%8C%EF%BC%89"><span class="nav-number">3.3.</span> <span class="nav-text">Kafka面试题整理（二）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E8%AF%B4%E6%98%8E%E4%BB%80%E4%B9%88%E6%98%AFApache-Kafka%EF%BC%9F"><span class="nav-number">3.3.1.</span> <span class="nav-text">请说明什么是Apache Kafka？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E8%AF%B4%E6%98%8E%E4%BB%80%E4%B9%88%E6%98%AF%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E6%96%B9%E6%B3%95%EF%BC%9F"><span class="nav-number">3.3.2.</span> <span class="nav-text">请说明什么是传统的消息传递方法？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E8%AF%B4%E6%98%8EKafka%E7%9B%B8%E5%AF%B9%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E6%96%B9%E6%B3%95%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E5%8A%BF%EF%BC%9F"><span class="nav-number">3.3.3.</span> <span class="nav-text">请说明Kafka相对于传统的消息传递方法有什么优势？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8Kafka%E4%B8%ADbroker%E7%9A%84%E6%84%8F%E4%B9%89%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">3.3.4.</span> <span class="nav-text">在Kafka中broker的意义是什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%83%BD%E6%8E%A5%E6%94%B6%E5%88%B0%E7%9A%84%E6%9C%80%E5%A4%A7%E4%BF%A1%E6%81%AF%E6%98%AF%E5%A4%9A%E5%B0%91%EF%BC%9F"><span class="nav-number">3.3.5.</span> <span class="nav-text">Kafka服务器能接收到的最大信息是多少？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E4%B8%AD%E7%9A%84ZooKeeper%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9FKafka%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E8%84%B1%E7%A6%BBZooKeeper%E7%8B%AC%E7%AB%8B%E8%BF%90%E8%A1%8C%EF%BC%9F"><span class="nav-number">3.3.6.</span> <span class="nav-text">Kafka中的ZooKeeper是什么？Kafka是否可以脱离ZooKeeper独立运行？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E9%87%8AKafka%E7%9A%84%E7%94%A8%E6%88%B7%E5%A6%82%E4%BD%95%E6%B6%88%E8%B4%B9%E4%BF%A1%E6%81%AF%EF%BC%9F"><span class="nav-number">3.3.7.</span> <span class="nav-text">解释Kafka的用户如何消费信息？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E8%BF%9C%E7%A8%8B%E7%94%A8%E6%88%B7%E7%9A%84%E5%90%9E%E5%90%90%E9%87%8F%EF%BC%9F"><span class="nav-number">3.3.8.</span> <span class="nav-text">解释如何提高远程用户的吞吐量？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A%E4%B8%80%E4%B8%8B%EF%BC%8C%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%88%B6%E4%BD%9C%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8C%E4%BD%A0%E5%A6%82%E4%BD%95%E8%83%BD%E4%BB%8EKafka%E5%BE%97%E5%88%B0%E5%87%86%E7%A1%AE%E7%9A%84%E4%BF%A1%E6%81%AF%EF%BC%9F"><span class="nav-number">3.3.9.</span> <span class="nav-text">解释一下，在数据制作过程中，你如何能从Kafka得到准确的信息？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E9%87%8A%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91ISR%E4%B8%AD%E7%9A%84%E6%89%B0%E5%8A%A8%EF%BC%9Fbroker%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E7%A6%BB%E5%BC%80ISR%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">3.3.10.</span> <span class="nav-text">解释如何减少ISR中的扰动？broker什么时候离开ISR？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%A4%8D%E5%88%B6%EF%BC%9F"><span class="nav-number">3.3.11.</span> <span class="nav-text">Kafka为什么需要复制？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E6%9E%9C%E5%89%AF%E6%9C%AC%E5%9C%A8ISR%E4%B8%AD%E5%81%9C%E7%95%99%E4%BA%86%E5%BE%88%E9%95%BF%E6%97%B6%E9%97%B4%E8%A1%A8%E6%98%8E%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">3.3.12.</span> <span class="nav-text">如果副本在ISR中停留了很长时间表明什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E8%AF%B4%E6%98%8E%E5%A6%82%E6%9E%9C%E9%A6%96%E9%80%89%E7%9A%84%E5%89%AF%E6%9C%AC%E4%B8%8D%E5%9C%A8ISR%E4%B8%AD%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">3.3.13.</span> <span class="nav-text">请说明如果首选的副本不在ISR中会发生什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E6%9C%89%E5%8F%AF%E8%83%BD%E5%9C%A8%E7%94%9F%E4%BA%A7%E5%90%8E%E5%8F%91%E7%94%9F%E6%B6%88%E6%81%AF%E5%81%8F%E7%A7%BB%E5%90%97%EF%BC%9F"><span class="nav-number">3.3.14.</span> <span class="nav-text">Kafka有可能在生产后发生消息偏移吗？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E8%AF%B4%E6%98%8EKafka-%E7%9A%84%E6%B6%88%E6%81%AF%E6%8A%95%E9%80%92%E4%BF%9D%E8%AF%81%EF%BC%88delivery-guarantee%EF%BC%89%E6%9C%BA%E5%88%B6%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">3.3.15.</span> <span class="nav-text">请说明Kafka 的消息投递保证（delivery guarantee）机制以及如何实现？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81Kafka%E7%9A%84%E6%B6%88%E6%81%AF%E6%9C%89%E5%BA%8F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">3.3.16.</span> <span class="nav-text">如何保证Kafka的消息有序（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98-%E5%8F%8A%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%EF%BC%9F"><span class="nav-number">3.3.17.</span> <span class="nav-text">kafka数据丢失问题,及如何保证？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka%E7%9A%84balance%E6%98%AF%E6%80%8E%E4%B9%88%E5%81%9A%E7%9A%84%EF%BC%9F"><span class="nav-number">3.3.18.</span> <span class="nav-text">kafka的balance是怎么做的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka%E7%9A%84%E6%B6%88%E8%B4%B9%E8%80%85%E6%96%B9%E5%BC%8F%EF%BC%9F"><span class="nav-number">3.3.19.</span> <span class="nav-text">kafka的消费者方式？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HBase"><span class="nav-number">4.</span> <span class="nav-text">HBase</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HBase%E6%9E%B6%E6%9E%84"><span class="nav-number">4.1.</span> <span class="nav-text">HBase架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86"><span class="nav-number">4.2.</span> <span class="nav-text">面试题整理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HBase%E7%9A%84%E7%89%B9%E7%82%B9%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">4.2.1.</span> <span class="nav-text">HBase的特点是什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HBase%E5%92%8CHive%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="nav-number">4.2.2.</span> <span class="nav-text">HBase和Hive的区别？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HBase%E9%80%82%E7%94%A8%E4%BA%8E%E6%80%8E%E6%A0%B7%E7%9A%84%E6%83%85%E6%99%AF%EF%BC%9F"><span class="nav-number">4.2.3.</span> <span class="nav-text">HBase适用于怎样的情景？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%8F%E8%BF%B0HBase%E7%9A%84rowKey%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.4.</span> <span class="nav-text">描述HBase的rowKey的设计原则？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%8F%E8%BF%B0HBase%E4%B8%ADscan%E5%92%8Cget%E7%9A%84%E5%8A%9F%E8%83%BD%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%BC%82%E5%90%8C%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.5.</span> <span class="nav-text">描述HBase中scan和get的功能以及实现的异同？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E6%8F%8F%E8%BF%B0HBase%E4%B8%ADscan%E5%AF%B9%E8%B1%A1%E7%9A%84setCache%E5%92%8CsetBatch%E6%96%B9%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.6.</span> <span class="nav-text">请描述HBase中scan对象的setCache和setBatch方法的使用？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E8%AF%A6%E7%BB%86%E6%8F%8F%E8%BF%B0HBase%E4%B8%AD%E4%B8%80%E4%B8%AAcell%E7%9A%84%E7%BB%93%E6%9E%84%EF%BC%9F"><span class="nav-number">4.2.7.</span> <span class="nav-text">请详细描述HBase中一个cell的结构？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E8%BF%B0HBase%E4%B8%ADcompact%E7%94%A8%E9%80%94%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%8C%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E8%A7%A6%E5%8F%91%EF%BC%8C%E5%88%86%E4%B8%BA%E5%93%AA%E4%B8%A4%E7%A7%8D%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.8.</span> <span class="nav-text">简述HBase中compact用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AF%8F%E5%A4%A9%E7%99%BE%E4%BA%BF%E6%95%B0%E6%8D%AE%E5%AD%98%E5%85%A5HBase%EF%BC%8C%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AD%98%E5%82%A8%E6%AD%A3%E7%A1%AE%E5%92%8C%E5%9C%A8%E8%A7%84%E5%AE%9A%E7%9A%84%E6%97%B6%E9%97%B4%E9%87%8C%E5%85%A8%E9%83%A8%E5%BD%95%E5%85%A5%E5%AE%8C%E6%AF%95%EF%BC%8C%E4%B8%8D%E6%AE%8B%E7%95%99%E6%95%B0%E6%8D%AE%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.9.</span> <span class="nav-text">每天百亿数据存入HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E5%88%97%E4%B8%BE%E5%87%A0%E4%B8%AAHBase%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.10.</span> <span class="nav-text">请列举几个HBase优化方法？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Region%E5%A6%82%E4%BD%95%E9%A2%84%E5%BB%BA%E5%88%86%E5%8C%BA%EF%BC%9F"><span class="nav-number">4.2.11.</span> <span class="nav-text">Region如何预建分区？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HRegionServer%E5%AE%95%E6%9C%BA%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.12.</span> <span class="nav-text">HRegionServer宕机如何处理？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HBase%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.13.</span> <span class="nav-text">HBase读写流程？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HBase%E5%86%85%E9%83%A8%E6%9C%BA%E5%88%B6%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">4.2.14.</span> <span class="nav-text">HBase内部机制是什么？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hbase%E4%B8%AD%E7%9A%84memstore%E6%98%AF%E7%94%A8%E6%9D%A5%E5%81%9A%E4%BB%80%E4%B9%88%E7%9A%84%EF%BC%9F"><span class="nav-number">4.2.15.</span> <span class="nav-text">Hbase中的memstore是用来做什么的？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HBase%E5%9C%A8%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%97%B6%E9%87%8D%E7%82%B9%E5%9C%A8%E4%BB%80%E4%B9%88%E5%9C%B0%E6%96%B9%EF%BC%9F%E4%B8%80%E5%BC%A0%E8%A1%A8%E4%B8%AD%E5%AE%9A%E4%B9%89%E5%A4%9A%E5%B0%91%E4%B8%AAColumn-Family%E6%9C%80%E5%90%88%E9%80%82%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.16.</span> <span class="nav-text">HBase在进行模型设计时重点在什么地方？一张表中定义多少个Column Family最合适？为什么？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98HBase%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E8%AF%BB%E5%86%99%E6%80%A7%E8%83%BD%EF%BC%9F%E8%AF%B7%E4%B8%BE%E4%BE%8B%E8%AF%B4%E6%98%8E%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.17.</span> <span class="nav-text">如何提高HBase客户端的读写性能？请举例说明（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HBase%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%EF%BC%9F"><span class="nav-number">4.2.18.</span> <span class="nav-text">HBase集群安装注意事项？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B4%E6%8E%A5%E5%B0%86%E6%97%B6%E9%97%B4%E6%88%B3%E4%BD%9C%E4%B8%BA%E8%A1%8C%E5%81%A5%EF%BC%8C%E5%9C%A8%E5%86%99%E5%85%A5%E5%8D%95%E4%B8%AAregion-%E6%97%B6%E5%80%99%E4%BC%9A%E5%8F%91%E7%94%9F%E7%83%AD%E7%82%B9%E9%97%AE%E9%A2%98%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E5%91%A2%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.19.</span> <span class="nav-text">直接将时间戳作为行健，在写入单个region 时候会发生热点问题，为什么呢？（☆☆☆☆☆）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%B7%E6%8F%8F%E8%BF%B0%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3HBase%E4%B8%ADregion%E5%A4%AA%E5%B0%8F%E5%92%8Cregion%E5%A4%AA%E5%A4%A7%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%86%B2%E7%AA%81%EF%BC%9F%EF%BC%88%E2%98%86%E2%98%86%E2%98%86%E2%98%86%E2%98%86%EF%BC%89"><span class="nav-number">4.2.20.</span> <span class="nav-text">请描述如何解决HBase中region太小和region太大带来的冲突？（☆☆☆☆☆）</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">cuanHaoQi</p>
  <div class="site-description" itemprop="description">时间顺流而下，生活逆水行舟</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">cuanHaoQi</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
